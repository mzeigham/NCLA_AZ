# -*- coding: utf-8 -*-
"""Tree+GHG+Crack+worst-first.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ac5YQM97P5AwHMhFrL0bVwP-YOAGVdAh
"""

import pandas as pd
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#from google.colab import drive
#drive.mount('/content/drive')

#import os
#os.chdir("drive/My Drive/Arizona Decision Tree") #change this to match your path
path = 'Network_GHG_Okte_V22.xlsm'
df = pd.read_excel(path)

# Load the GIS shapefile
shapefile_path = 'arizona_10_11.shp'
gdf = gpd.read_file(shapefile_path)

#Do not change these functions
def import_LCI_library(path):
    """
    Import and process the LCI (Life Cycle Inventory) library from an Excel file.

    :param path: String, path to the Excel file (default: 'files/Network GHG_Okte.xlsm')
    :return: pandas DataFrame, processed LCI library data
    """

    # Define the path to the Excel file
    file_path = path

    # Load the "Library" sheet from the Excel file
    # The header=4 parameter skips the first 4 rows, assuming the actual data starts from the 5th row
    library_df = pd.read_excel(file_path, sheet_name='Library', header=4)

    # Select all required columns in one step
    # This assumes that the first 16 columns (0-15) contain the relevant data
    LCI_library = library_df.iloc[:, [0,1,2,3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]

    # Define the correct column names for the selected data
    column_names = ['from', 'unique_id', 'type', 'name', 'measure_type', 'quantity', 'units',
                    'mass_conversion_factor', 'fuel_type', 'horsepower_range', 'mass_short_tons',
                    'agency_id', 'description', 'editable', 'from_epd', 'global_warming_kg_co2_eq']

    # Rename the columns of the DataFrame with the correct headers
    LCI_library.columns = column_names

    # Return the processed LCI library DataFrame
    return LCI_library

def import_draft_treatments(path):
    """
    Import and process draft treatments data from an Excel file.

    :param path: String, path to the Excel file (default: 'files/Network GHG_Okte.xlsm')
    :return: Dictionary, processed treatments data
    """

    # Define the path to the Excel file
    file_path = path

    # Load the "Treat" sheet from the Excel file
    Items = pd.read_excel(file_path, sheet_name='Treat')

    # Define the stages and corresponding processes
    Stages = ['A1', 'A2', 'A3', 'A4', 'A5', 'C2']
    Processes = ['Material', 'Transport', 'Material_Process', 'Transport', 'Equipment', 'Transport']

    # Define column ranges for each stage
    RangesDict = {
        'A1': [19, 66],   # Material
        'A2': [67, 127],  # Transport
        'A3': [127, 139], # Material Process
        'A4': [139, 199], # Transport
        'A5': [199, 259], # Equipment
        'C2': [259, -1]   # Transport
    }

    # Define row indices
    rowitem = 2
    firstrow = 4
    lastrow = 21  # where materials end
    columnstart = 19  # where A1, A2, etc. starts

    # Define item properties for each stage
    ItemsDict = {
        'A1': {'Name': 'Name', 'Unit': 'Unit', 'Qty': 'Qty', 'GHG_kg': 'GHG (kg CO2eq.)'},
        'A2': {'Name': 'Name', 'Unit': 'Unit', 'Qty': 'Qty', 'GHG_kg': 'GHG (kg CO2eq.)', 'Dist_mi': 'Dist. (miles)'},
        'A3': {'Name': 'Name', 'Unit': 'Unit', 'Qty': 'Qty', 'GHG_kg': 'GHG (kg CO2eq.)'},
        'A4': {'Name': 'Name', 'Unit': 'Unit', 'Qty': 'Qty', 'GHG_kg': 'GHG (kg CO2eq.)', 'Dist_mi': 'Dist. (miles)'},
        'A5': {'Name': 'Name', 'Unit': 'Unit', 'Qty': 'Qty', 'GHG_kg': 'GHG (kg CO2eq.)', 'Weight_tons': 'Weight (tons)'},
        'C2': {'Name': 'Name', 'Unit': 'Unit', 'Qty': 'Qty', 'GHG_kg': 'GHG (kg CO2eq.)', 'Dist_mi': 'Dist. (miles)'}
    }

    # Calculate the maximum number of items for each stage
    MaxDict = {stage: len(Items.iloc[rowitem, RangesDict[stage][0]:RangesDict[stage][1]].dropna()) for stage in Stages}

    # Define generic columns for treatment information
    GenericColumns = ['Description', 'Budget_Category', 'Cost_lane_mi', 'Roughness', 'Rutting', 'Cracking', 'Faulting',
                      'Years_to_pretreatment_crack', 'years_crack_at_zero', 'years_to_pretreatment_rutting', 'years_rutting_at_zero']

    # Initialize the Treatments dictionary
    Treatments = {}

    # Iterate through each row (treatment) in the Excel sheet
    for i in range(firstrow, lastrow + 1):
        treatment_name = Items.iloc[i, 0]
        Treatments[treatment_name] = {}

        # Add generic information for the treatment
        for j, column in enumerate(GenericColumns):
            Treatments[treatment_name][column] = Items.iloc[i, j + 1]

        colcounter = 0
        # Process each stage (A1 to C2) for the treatment
        for k, stage in enumerate(Stages):
            Treatments[treatment_name][stage] = {Processes[k]: []}

            # Process each item within the stage
            for t in range(MaxDict[stage]):
                if pd.isna(Items.iloc[i, columnstart + colcounter]):  # Check if the item name is empty
                    colcounter += len(ItemsDict[stage])
                    continue

                # Create a new item dictionary and populate it
                item_dict = {}
                for r, (key, value) in enumerate(ItemsDict[stage].items()):
                    item_dict[key] = Items.iloc[i, columnstart + colcounter + r]

                Treatments[treatment_name][stage][Processes[k]].append(item_dict)
                colcounter += len(ItemsDict[stage])

    return Treatments

def calculate_ghg_emissions(treatments, lci_library, project_area=1, material_distance=25, mill_distance=25, equipment_distance=15, equipment_dist_divider=7040, specific_treatment=None):
    """
    Calculate GHG emissions for treatments and add an 'emissions' key with sub-keys for each stage and total.

    :param treatments: Dictionary containing treatment data
    :param lci_library: DataFrame containing LCI library data
    :param project_area: Project area in square yards (default 1)
    :param material_distance: Distance of material haul in miles (default 25)
    :param mill_distance: Distance of milled material haul in miles (default 25)
    :param equipment_distance: Distance of equipment haul in miles (default 15)
    :param equipment_dist_divider: Divider for equipment transport (default 7040)
    :param specific_treatment: Name of a specific treatment to calculate (default None, calculates all)
    :return: Updated treatments dictionary with GHG calculations and emissions summary
    """

    treatment_names = [specific_treatment] if specific_treatment else list(treatments.keys())

    for treatment_name in treatment_names:
        if treatment_name not in treatments:
            print(f"Warning: Treatment '{treatment_name}' not found in the treatments dictionary.")
            continue

        treatment = treatments[treatment_name]

        # Initialize emissions dictionary for this treatment
        treatment['emissions'] = {
            'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'C2': 0, 'total': 0
        }

        total_mat_weight = sum(item['Qty'] for item in treatment['A1']['Material'])
        total_equip_weight = sum(item['Weight_tons'] for item in treatment['A5']['Equipment'])

        # A1: Materials
        for material in treatment['A1']['Material']:
            libraryname = material['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = material['Qty']
            material['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['A1'] += material['GHG_kg']

        # A2: Transport
        for transport in treatment['A2']['Transport']:
            libraryname = transport['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = transport['Qty']
            transport['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['A2'] += transport['GHG_kg']

        # A3: Material Process
        for process in treatment['A3']['Material_Process']:
            libraryname = process['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = process['Qty']
            process['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['A3'] += process['GHG_kg']

        # A4: Transport
        if len(treatment['A4']['Transport']) > 0:
            # Material transfer
            mat_transport = treatment['A4']['Transport'][0]
            libraryname = mat_transport['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = total_mat_weight * material_distance
            mat_transport['Dist_mi'] = material_distance
            mat_transport['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['A4'] += mat_transport['GHG_kg']

            # Equipment transfer
            equip_transport = treatment['A4']['Transport'][1]
            libraryname = equip_transport['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = total_equip_weight * equipment_distance / equipment_dist_divider
            equip_transport['Dist_mi'] = equipment_distance
            equip_transport['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['A4'] += equip_transport['GHG_kg']

        # A5: Equipment
        for equipment in treatment['A5']['Equipment']:
            libraryname = equipment['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = equipment['Qty']
            equipment['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['A5'] += equipment['GHG_kg']

        # C2: Transport (milling)
        for transport in treatment['C2']['Transport']:
            libraryname = transport['Name']
            unitghg = lci_library.loc[lci_library['name'] == libraryname, 'global_warming_kg_co2_eq'].values[0]
            qty = treatment['A1']['Material'][0]['Qty'] * mill_distance  # first A1 material is being milled away
            transport['Dist_mi'] = mill_distance
            transport['GHG_kg'] = unitghg * qty * project_area
            treatment['emissions']['C2'] += transport['GHG_kg']

        # Calculate total emissions
        treatment['emissions']['total'] = sum(treatment['emissions'][stage] for stage in ['A1', 'A2', 'A3', 'A4', 'A5', 'C2'])

    return treatments

def create_emissions_table(treatments):
    """
    Create a table of treatment names and their emissions by stage and total.

    :param treatments: Dictionary containing treatment data with emissions calculations
    :return: pandas DataFrame with emissions data
    """
    data = []
    for treatment_name, treatment_data in treatments.items():
        if 'emissions' in treatment_data:
            row = {
                'Treatment': treatment_name,
                'A1': treatment_data['emissions']['A1'],
                'A2': treatment_data['emissions']['A2'],
                'A3': treatment_data['emissions']['A3'],
                'A4': treatment_data['emissions']['A4'],
                'A5': treatment_data['emissions']['A5'],
                'C2': treatment_data['emissions']['C2'],
                'Total': treatment_data['emissions']['total']
            }
            data.append(row)

    df = pd.DataFrame(data)
    df = df.set_index('Treatment')
    return df

def plot_emissions_bar_chart(treatments, selected_treatments=None):
    """
    Create a side-by-side bar chart of percent emissions contributions by stage for selected treatments using seaborn.

    :param treatments: Dictionary containing treatment data with emissions calculations
    :param selected_treatments: List of treatment names or a single treatment name to include in the plot (default None, plots all treatments)
    :return: None (displays the plot)
    """
    if selected_treatments is None:
        selected_treatments = list(treatments.keys())
    elif isinstance(selected_treatments, str):
        selected_treatments = [selected_treatments]

    data = []
    stages = ['A1', 'A2', 'A3', 'A4', 'A5', 'C2']
    for treatment in selected_treatments:
        if treatment in treatments and 'emissions' in treatments[treatment]:
            emissions = treatments[treatment]['emissions']
            total_emission = sum(emissions[stage] for stage in stages)
            for stage in stages:
                percent_contribution = (emissions[stage] / total_emission) * 100 if total_emission > 0 else 0
                data.append({
                    'Treatment': treatment,
                    'Stage': stage,
                    'Percent Contribution': percent_contribution
                })

    if not data:
        print("No valid treatments found with emissions data.")
        return

    df = pd.DataFrame(data)

    plt.figure(figsize=(15, 8))
    ax = sns.barplot(x='Treatment', y='Percent Contribution', hue='Stage', data=df)

    # Add percentage labels on top of each bar
    for container in ax.containers:
        ax.bar_label(container, fmt='%.1f%%', label_type='edge')

    plt.title('Percent Emissions Contribution by Stage for Selected Treatments')
    plt.xlabel('Treatments')
    plt.ylabel('Percent Contribution')
    plt.legend(title='Stages', bbox_to_anchor=(1.05, 1), loc='upper left')

    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

LCI_library=import_LCI_library(path)
draft_treatments=import_draft_treatments(path)
Treatments=calculate_ghg_emissions(draft_treatments, LCI_library, project_area=1, material_distance=25, mill_distance=25, equipment_distance=15, equipment_dist_divider=7040, specific_treatment=None)

# Modify emissions for 'SR_3INCH_AC_MS' and 'RECONSTRUCTION'
def adjust_emissions(treatment_table):
    # Set emissions for 'SR_3INCH_AC_MS' equal to 'MS_2_PASS'
    if 'MS_2_PASS' in treatment_table.index and 'SR_3INCH_AC_MS' in treatment_table.index:
        treatment_table.loc['SR_3INCH_AC_MS'] = treatment_table.loc['MS_2_PASS']

    # Set emissions for 'RECONSTRUCTION' equal to 'RR_5INCH_AC_FR' + 'CRACKSEAL_AND_CHIPSEAL'
    if 'RR_5INCH_AC_FR' in treatment_table.index and 'CRACKSEAL_AND_CHIPSEAL' in treatment_table.index and 'RECONSTRUCTION' in treatment_table.index:
        treatment_table.loc['RECONSTRUCTION'] = (
            treatment_table.loc['RR_5INCH_AC_FR'] + treatment_table.loc['CRACKSEAL_AND_CHIPSEAL']
        )

    return treatment_table

Treatment_Table=create_emissions_table(Treatments) #per squareyd
Treatment_Table = adjust_emissions(Treatment_Table)
Treatment_Table

import pandas as pd

Treatment_Table_LaneMile = Treatment_Table.copy()
numeric_cols = Treatment_Table_LaneMile.select_dtypes(include=['float', 'int']).columns
# Multiply values by 7040
Treatment_Table_LaneMile[numeric_cols] = Treatment_Table_LaneMile[numeric_cols] * 7040
# Format the numbers in scientific notation using DataFrame.astype
Treatment_Table_LaneMile[numeric_cols] = Treatment_Table_LaneMile[numeric_cols].astype(float).map(lambda x: f"{x/1e3:.3f}E03")

Treatment_Table_LaneMile

sns.set()
plot_emissions_bar_chart(Treatments, selected_treatments='RR_0p5INCH_FR')

sns.set()
# Modify the code to work with a DataFrame called Treatment_Table

# Assuming Treatment_Table is provided with the correct structure as per the user’s description
# First, we'll clean up the table, remove zero totals, and shorten treatment names

# Clean up: removing treatments with zero total contribution and simplifying long names
Treatment_Table_clean = Treatment_Table[Treatment_Table['Total'] > 0].copy()

# Simplify the treatment names for better readability
Treatment_Table_clean.index = Treatment_Table_clean.index.str.replace('CRACKSEAL_AND_CHIPSEAL', 'CS & Chipseal') \
                                                    .str.replace('MILL_FR_AND_MICRO_CAPE_SEAL', 'Mill FR & Micro Cape Seal') \
                                                    .str.replace('MAJOR_REHAB_OR_RECONSTRUCTION', 'Major Rehab') \
                                                    .str.replace('RR_0p5INCH_FR', 'RR 0.5" FR') \
                                                    .str.replace('RR_1INCH_FR', 'RR 1" FR') \
                                                    .str.replace('RR_2INCH_AC_FR', 'RR 2" AC FR') \
                                                    .str.replace('RR_2p5INCH_AC_FR', 'RR 2.5" AC FR') \
                                                    .str.replace('RR_3INCH_AC_FR', 'RR 3" AC FR') \
                                                    .str.replace('RR_4INCH_AC_FR', 'RR 4" AC FR') \
                                                    .str.replace('RR_5INCH_AC_FR', 'RR 5" AC FR')

# Recalculate percentages for each stage relative to the total
Treatment_Table_percentage = Treatment_Table_clean[['A1', 'A2', 'A3', 'A4', 'A5', 'C2']].div(Treatment_Table_clean['Total'], axis=0) * 100

# Plot the stacked bar chart for percentage values
ax = Treatment_Table_percentage.plot(kind='bar', stacked=True, figsize=(12, 8))

# Add totals on top of the bars
for i in range(len(Treatment_Table_clean)):
    total = Treatment_Table_clean['Total'].iloc[i]
    ax.text(i, 100, f'{total:.1f}', ha='center', va='bottom', fontsize=12, weight='bold')

# Customization of the chart
plt.title('Treatment GHG per sqyd (Total Displayed at the Top)', fontsize=16)
plt.ylabel('Percentage Contribution (%)', fontsize=14)
plt.xlabel('Treatment', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.legend(title='LCA Stages', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)
plt.tight_layout()

# Show the plot
plt.show()



# Number_of_Trucks Calculation
gdf['Number_of_Trucks'] = np.select(
    [
        gdf['Functional'].isin([1, 2]),  # Condition for Functional class values 1 and 2
        gdf['Functional'].isin([11, 12]),  # Condition for Functional class values 11 and 12
        gdf['Functional'].isin([3, 4]),  # Condition for Functional class values 3 and 4
        gdf['Functional'].isin([14]),  # Condition for Functional class value 14
        gdf['Functional'].isin([6, 7, 8, 9]),  # Condition for Functional class values 6, 7, 8, 9
        gdf['Functional'].isin([16, 17, 18, 19])  # Condition for Functional class values 16, 17, 18, 19
    ],
    [0.2391,  # Value for Functional 1 and 2
    0.0837,  # Value for Functional 11 and 12
    0.0740,  # Value for Functional 3 and 4
    0.0224,  # Value for Functional 14
    0.0339,  # Value for Functional 6, 7, 8, 9
    0.0054  # Value for Functional 16, 17, 18, 19
    ],
    default=0  # Default value if no condition matches
)

# Check if Functional class is 1 or 2 and define VCD values accordingly
#VCD values are coming from Table A-1
if gdf['Functional'].isin([1, 2]).all():
    # Use VCD values for Functional classes 1 or 2 which is AZ-5 in table A-1
    VCD_values = {
        4: 5.3, 5: 46.3, 6: 5.7, 7: 0.7, 8: 16.1, 9: 24.1, 10: 1.1, 11: 0.3, 12: 0.1, 13: 0.3
    }
else:
    # Use VCD values for other Functional classes which is AZ-6 in table A-1
    VCD_values = {
        4: 7.8, 5: 65.8, 6: 4.4, 7: 0.2, 8: 11.7, 9: 9.1, 10: 0.7, 11: 0.2, 12: 0.0, 13: 0.1
    }


# Define TF values based on Functional class groups
#These values are coming from Table A-5
TF_values = {
    (1, 11): {4: 1.07, 5: 0.33, 6: 0.64, 7: 0.58, 8: 0.61, 9: 1.62, 10: 1.43, 11: 1.75, 12: 1.31, 13: 3.51},
    (2, 6, 8, 9, 12, 16, 18, 19): {4: 1.06, 5: 0.39, 6: 0.96, 7: 0.61, 8: 0.91, 9: 1.34, 10: 1.53, 11: 1.96, 12: 1.33, 13: 3.50},
    (4, 14): {4: 1.20, 5: 0.13, 6: 0.86, 7: 0.64, 8: 0.52, 9: 1.93, 10: 1.78, 11: 2.25, 12: 1.17, 13: 2.07}
}

# Function to get the TF value based on Functional class and ESAL class
def get_TF_value(row, class_number):
    for functional_group, class_TF in TF_values.items():
        if row['Functional'] in functional_group:
            return class_TF.get(class_number, 1.0)  # Default to 1.0 if class_number not found
    return 1.0  # Default TF value

# Calculate DD and LD based on lanes
gdf['lanes'] = gdf['Number_of_'] * 2
gdf['DD'] = np.select(
    [gdf['lanes'] == 2, gdf['lanes'] == 4, gdf['lanes'] >= 6],
    [0.5, 0.45, 0.4],
    default=None  # Default value remains None
)
gdf['LD'] = np.select(
    [gdf['Number_of_'] == 1, gdf['Number_of_'] == 2, gdf['Number_of_'] == 3, gdf['Number_of_'] >= 4],
    [1, 0.9, 0.8, 0.7],
    default=None  # Default value remains None
)

# Define traffic growth factor (TGF)
annual_traffic_growth = 0.00001  # Traffic growth assumption
year = 20
tgf = (((1 + annual_traffic_growth) ** year) - 1) / annual_traffic_growth

# ESAL Calculation Function
def esal_20_year(gdf):
    # Initialize a column to store the total ESAL for 20 years
    gdf['ESAL_20_year'] = 0

    # Calculate ESAL for each class using VCD and TF values and sum them
    for class_number, vcd in VCD_values.items():
        # Calculate the corresponding TF for each row
        tf_values = gdf.apply(lambda row: get_TF_value(row, class_number), axis=1)

        # Compute ESAL for the current class and add it to the total ESAL
        gdf['ESAL_20_year'] += (vcd * tf_values * gdf['AADT'] * gdf['Number_of_Trucks'] * gdf['DD'] * gdf['LD'] * tgf * 365/100)

    return gdf

# Run the ESAL calculation function to add the 'esal_20_year' column
gdf = esal_20_year(gdf)

# Calculate Pavement Family
gdf['first_digit'] = np.where(gdf['PAVEMENT_T'] == 'AC', '1', np.where(gdf['PAVEMENT_T'] == 'Other', '2', '0'))
climate_assumption = '1'
gdf['second_digit'] = climate_assumption
gdf['third_digit'] = np.select(
    [gdf['ESAL_20_year'] < 300000,
     (gdf['ESAL_20_year'] >= 300000) & (gdf['ESAL_20_year'] < 3000000),
     (gdf['ESAL_20_year'] >= 3000000) & (gdf['ESAL_20_year'] < 10000000),
     (gdf['ESAL_20_year'] >= 10000000) & (gdf['ESAL_20_year'] < 30000000),
     gdf['ESAL_20_year'] >= 30000000],
    ['1', '2', '3', '4', '5'],
    default='0'
)
foundation_assumption = '1'
gdf['fourth_digit'] = foundation_assumption
gdf['Pavement_Family'] = gdf['first_digit'] + gdf['second_digit'] + gdf['third_digit'] + gdf['fourth_digit']

# Vectorized calculation for Delta Rutting and Delta IRI
# svf
gdf['svf'] = np.where(gdf['Pavement_Family'].str[1] == '1', 0.75, 3.25)

"""Crack Progression Calculation"""

# Define the coefficients for IRI and Rutting based on Pavement Family
base_coefficients = {
    '11': {'IRI': {'a': 0.254, 'b': 0, 'c': 3.73},
           'Rutting': {'a': 0.0003, 'b': 0.0014, 'c': 0.004}},
    '12': {'IRI': {'a': 0.272, 'b': 0, 'c': 1.57},
           'Rutting': {'a': 0.0003, 'b': 0.0009, 'c': 0.0014}},
    '21': {'IRI': {'a': 0, 'b': 0.3, 'c': 3.6},
           'Rutting': {'a': 0.0006, 'b': 0.0006, 'c': 0}},
    '22': {'IRI': {'a': 0, 'b': 0.3, 'c': 3.6},
           'Rutting': {'a': 0.0006, 'b': 0.005, 'c': 0}},
    '1141': {'IRI': {'a': 0.254, 'b': 0, 'c': 3.73},
             'Rutting': {'a': 0.0004, 'b': 0.025, 'c': 0}}
}
# Apply coefficients from the base_coefficients dictionary
def get_rutting_coefficients(pavement_family):
    prefix = str(pavement_family)[:2]
    if prefix[0] == '0':
        return None, None, None
    coeffs = base_coefficients.get(prefix, {}).get('Rutting', {})
    return coeffs.get('a', None), coeffs.get('b', None), coeffs.get('c', None)

def get_iri_coefficients(pavement_family):
    prefix = str(pavement_family)[:2]
    if prefix[0] == '0':
        return None, None, None
    coeffs = base_coefficients.get(prefix, {}).get('IRI', {})
    return coeffs.get('a', None), coeffs.get('b', None), coeffs.get('c', None)

# Vectorized calculation of Delta Rutting
gdf['a_rutting'], gdf['b_rutting'], gdf['c_rutting'] = zip(*gdf['Pavement_Family'].apply(get_rutting_coefficients))
gdf['delta_rutting'] = gdf['a_rutting'] * 1 + (gdf['b_rutting'] * gdf['ESAL_20_year'] / 20000000) + (gdf['c_rutting'] * gdf['svf'])

# Vectorized calculation of Delta IRI
gdf['a_iri'], gdf['b_iri'], gdf['c_iri'] = zip(*gdf['Pavement_Family'].apply(get_iri_coefficients))
gdf['delta_iri'] = gdf['a_iri'] * 1 + (gdf['b_iri'] * gdf['ESAL_20_year'] / 20000000) + (gdf['c_iri'] * gdf['svf'])


gdf.drop(columns=['a_rutting', 'b_rutting', 'c_rutting', 'a_iri', 'b_iri', 'c_iri'], inplace=True)

# Now calculate future IRI and Rutting for enxt years
for years in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:
    gdf[f'Rutting_after_{years}_y'] = gdf['Rutting'] + gdf['delta_rutting'] * years
    gdf[f'IRI_after_{years}_y'] = gdf['AvgIRI'] + gdf['delta_iri'] * years


# Display the Rutting Predictions Table
def display_rutting_table(gdf):
    rutting_table = gdf[['Pavement_Family', 'Rutting', 'delta_rutting'] +
                        [f'Rutting_after_{year}_y' for year in range(1, 11)]]
    print(rutting_table.head(15).to_string(index=False))

# Display the IRI Predictions Table
def display_iri_table(gdf):
    iri_table = gdf[['Pavement_Family', 'AvgIRI', 'delta_iri'] +
                    [f'IRI_after_{year}_y' for year in range(1, 11)]]
    print(iri_table.head(15).to_string(index=False))

# Display the tables using gdf
display_rutting_table(gdf)
display_iri_table(gdf)

# Apply ESAL capping based on Pavement Family
def cap_esal(row):
    if row['Pavement_Family'].startswith("11"):
        return min(row['ESAL_20_year'], 30000000)
    elif row['Pavement_Family'] == "1141":
        return min(row['ESAL_20_year'], 24000000)
    elif row['Pavement_Family'].startswith("21"):
        return min(row['ESAL_20_year'], 380000000)
    return row['ESAL_20_year']

# Apply the function to cap ESAL values
gdf['ESAL_20_year'] = gdf.apply(cap_esal, axis=1)

gdf['first_digit'] = np.where(gdf['PAVEMENT_T'] == 'AC', '1', np.where(gdf['PAVEMENT_T'] == 'Other', '2', '0'))
climate_assumption = '1'
gdf['second_digit'] = climate_assumption
gdf['third_digit'] = np.select([
    gdf['ESAL_20_year'] < 300000,
    (gdf['ESAL_20_year'] >= 300000) & (gdf['ESAL_20_year'] < 3000000),
    (gdf['ESAL_20_year'] >= 3000000) & (gdf['ESAL_20_year'] < 10000000),
    (gdf['ESAL_20_year'] >= 10000000) & (gdf['ESAL_20_year'] < 30000000),
    gdf['ESAL_20_year'] >= 30000000
], ['1', '2', '3', '4', '5'], default='0')

foundation_assumption = '1'
gdf['fourth_digit'] = foundation_assumption
gdf['Pavement_Family'] = gdf['first_digit'] + gdf['second_digit'] + gdf['third_digit'] + gdf['fourth_digit']

# SVF Calculation
gdf['svf'] = np.where(gdf['Pavement_Family'].str[1] == '1', 0.75, 3.25)

# Define Coefficients
base_coefficients_hpms = {
    '11': {'a': 0.45, 'b': 0.07, 'c': 0.02, 'd': 0.05},
    '12': {'a': 0.45, 'b': 0.14, 'c': 0.02, 'd': 0.05},
    '21': {'a': 0.45, 'b': 0.02, 'c': 0.03, 'd': 0.02},
    '22': {'a': 0.45, 'b': 0.02, 'c': 0.02, 'd': 0.02},
    '1141': {'a': 0.45, 'b': 0.13, 'c': 0.02, 'd': 0.05}
}

def get_coefficients(pavement_family):

    pavement_family = str(pavement_family)  # Ensure it's a string

    # Extract the first two digits
    first_two_digits = pavement_family[:2]

    # Check if the first two digits exist in the coefficient dictionary
    if first_two_digits in base_coefficients_hpms:
        return base_coefficients_hpms[first_two_digits]

    return {'a': 0, 'b': 0, 'c': 0, 'd': 0}  # Default coefficients

def Crack(Age, ESAL, pavement_family, SVF):
    coeffs = get_coefficients(pavement_family)
    a, b, c, d = coeffs['a'], coeffs['b'], coeffs['c'], coeffs['d']
    ESAL_DEF = 20 * 10**6
    Crack_prog = np.zeros(int(Age))

    for i in range(1, min(int(Age), 100)):  # Ensuring max age cap
        growth_factor = max(1.002, 1 + a + b * ESAL / ESAL_DEF - c * i)
        Crack_prog[i] = Crack_prog[i - 1] * growth_factor + d * SVF
        Crack_prog[i] = min(Crack_prog[i], 100)  # Ensure crack does not exceed 100%

    return Crack_prog

# Pre-allocate arrays
pavement_families = gdf['Pavement_Family'].values
SVF_values = gdf['svf'].values
ESAL_values = gdf['ESAL_20_year'].values
HPMS_Crack_values = gdf['HPMS_Crack'].values
n_rows = len(ESAL_values)

interpolated_ages_list = []

for idx in range(n_rows):
    ESAL = ESAL_values[idx]  # Use already capped ESAL
    HPMS_Crack = HPMS_Crack_values[idx]
    pavement_family = pavement_families[idx]
    SVF = SVF_values[idx]


    cracks = Crack(100, ESAL=ESAL, pavement_family=pavement_family, SVF=SVF)

    # Define max age for each pavement family
    max_age = 100

    interpolated_age = int(np.interp(HPMS_Crack, cracks, np.arange(100)))
    interpolated_age = min(interpolated_age, max_age)

    interpolated_ages_list.append(interpolated_age)

gdf['Interpolated_Age'] = interpolated_ages_list

print(gdf[['HPMS_Crack', 'Interpolated_Age', 'ESAL_20_year', 'svf', 'Pavement_Family']].head(20).to_string(index=False))

# Function to calculate HPMS Crack Progression
def compute_hpms_crack_projection(Age, ESAL, pavement_family, SVF, initial_HPMS_Crack, years=10):
    coeffs = get_coefficients(pavement_family)
    a, b, c, d = coeffs['a'], coeffs['b'], coeffs['c'], coeffs['d']
    ESAL_DEF = 20000000

    hpms_crack_prog = [initial_HPMS_Crack]

    for t in range(1, years + 1):
        growth_factor = max(1.002, (1 + a + b * (ESAL / ESAL_DEF) - c * (Age + t - 1)))
        next_crack = hpms_crack_prog[t - 1] * growth_factor + d * SVF
        next_crack = min(next_crack, 100)  # Ensure crack does not exceed 100%
        hpms_crack_prog.append(next_crack)

    return hpms_crack_prog

# Apply function for each row
projection_years = 10
hpms_crack_projections = []

for idx in range(n_rows):
    Age = interpolated_ages_list[idx] + 1  # Using interpolated age
    ESAL = ESAL_values[idx]  # Already capped ESAL
    pavement_family = pavement_families[idx]
    SVF = SVF_values[idx]
    initial_HPMS_Crack = gdf['HPMS_Crack'].iloc[idx]

    crack_progression = compute_hpms_crack_projection(Age, ESAL, pavement_family, SVF, initial_HPMS_Crack, years=projection_years)
    hpms_crack_projections.append(crack_progression)

# Convert list to DataFrame and add to gdf
years_columns = [f'HPMS_Crack_Year_{i}' for i in range(projection_years + 1)]
hpms_crack_df = pd.DataFrame(hpms_crack_projections, columns=years_columns)
gdf = pd.concat([gdf, hpms_crack_df], axis=1)

# Display results
print(gdf[['HPMS_Crack'] + years_columns].head(20).to_string(index=False))
print(gdf[['Interpolated_Age']].head(20).to_string(index=False))

treatments = import_draft_treatments(path)

for treatment_name, treatment_data in treatments.items():
    cost_lane_mi = treatment_data.get('Cost_lane_mi')
    print(f"Treatment: {treatment_name}, Cost_lane_mi: {cost_lane_mi}")

gdf['New_Rutting']=gdf['Rutting']
gdf['New_AvgIRI']=gdf['AvgIRI']
gdf['New_HPMS_Cracking']=gdf['HPMS_Crack']

class Node:
    def __init__(self, question, yes_branch, no_branch):
        self.question = question
        self.yes_branch = yes_branch
        self.no_branch = no_branch

    def decide(self, row):
        if self.question(row):
            return self.yes_branch.decide(row) if isinstance(self.yes_branch, Node) else self.yes_branch
        else:
            return self.no_branch.decide(row) if isinstance(self.no_branch, Node) else self.no_branch


# Define the questions as functions
def is_JPCP_or_CRCP(row):
  return row['PAVEMENT_T'] in ['JPCP', 'CRCP']


def is_IRI_above_143_or_faulting_above_015(row):
  return row['New_AvgIRI']>143 #or row['JPCP_JPCPF']>0.15

def is_faulting_above_01_or_crack_above_5(row):
  return row['New_HPMS_Cracking']>5 #or row['JPCP_JPCPF']>0.1



def is_ACOL_or_JPCPFC_or_CRCPFC(row):
  return row['PAVEMENT_T'] in ['Other', 'CRCP+FC', 'JPCP+FC']

gdf['No_of_Rehab']=0
gdf['Foundation_Issue']=0
def is_no_of_rehabilitation_equal_above_3_or_foundation_issue_equal_1(row):
  return row['No_of_Rehab']>=3 or row['Foundation_Issue']==1

def is_predicted_crack_above_12_or_rutting_above_04_or_IRI_above_105(row):
  return row['New_HPMS_Cracking']>12 or row['New_Rutting']>0.4 or row['New_AvgIRI']>105

def is_predicted_crack_above_15_or_rutting_above_04_or_IRI_above_143(row):
  return row['New_HPMS_Cracking']>15 or row['New_Rutting']>0.4 or row['New_AvgIRI']>143



def is_IRI_above_143(row):
  return row['New_AvgIRI']>143


def is_crack_above_5(row):
  return row['New_HPMS_Cracking']>5

def is_crack_under_5(row):
  return row['New_HPMS_Cracking']<5

def is_crack_equal_above_2(row):
  return row['New_HPMS_Cracking']>=2

def is_crack_under_8(row):
  return row['New_HPMS_Cracking']<8



def is_rutting_above_01(row):
  return row['New_Rutting']>0.1


def is_interstate(row):
  return row['Functional']==1 or row['Functional']==11


def is_AADT_above_15000(row):
  return row['AADT']>15000

def is_AADT_above_10000(row):
  return row['AADT']>10000

def is_AADT_above_5000(row):
  return row['AADT']>5000

def is_AADT_above_3000(row):
  return row['AADT']>3000

def is_AADT_above_1000(row):
  return row['AADT']>1000


gdf['SCHD_Year'] = 0
def is_SCHD_expiration_year_9(row):
  return row['SCHD_Year']>=9

def is_SCHD_expiration_year_8(row):
  return row['SCHD_Year']>=8

def is_SCHD_expiration_year_7(row):
  return row['SCHD_Year']>=7

def is_SCHD_expiration_year_3(row):
  return row['SCHD_Year']>=3


def is_poor_IRI_or_cracking_or_rutting_above_40(row):
    return row['IRI_Rating']==3 or row['Cracking_R']==3 or row['Rutting_Ra']==3




#Building the decision tree
tree = Node(is_JPCP_or_CRCP,
            Node(is_IRI_above_143_or_faulting_above_015, 'DIAMOND_GRIND',
                      Node(is_faulting_above_01_or_crack_above_5, 'REPAIR', 'DO_NOTHING')),
            Node(is_poor_IRI_or_cracking_or_rutting_above_40,
                 Node(is_ACOL_or_JPCPFC_or_CRCPFC,
                      Node(is_no_of_rehabilitation_equal_above_3_or_foundation_issue_equal_1, 'RECONSTRUCTION_OR_RR_1INCH_FR', 'RR_1INCH_FR'),
                      Node(is_no_of_rehabilitation_equal_above_3_or_foundation_issue_equal_1,
                           Node(is_interstate, 'RECONSTRUCTION_OR_RR_5INCH_AC_FR_OR_RR_3INCH_AC_FR',
                                Node(is_AADT_above_15000, 'RECONSTRUCTION_OR_RR_4INCH_AC_FR_OR_RR_3INCH_AC_FR', 'RR_3INCH_AC_FR')),
                           Node(is_interstate,
                                Node(is_predicted_crack_above_12_or_rutting_above_04_or_IRI_above_105,
                                     Node(is_AADT_above_10000, 'RR_5INCH_AC_FR_OR_RR_3INCH_AC_FR',
                                          Node(is_AADT_above_5000, 'RR_4INCH_AC_FR_OR_RR_3INCH_AC_FR', 'RR_3INCH_AC_FR')),
                                     Node(is_AADT_above_5000,
                                          Node(is_SCHD_expiration_year_9, 'SR_3INCH_AC_MS', 'CONTINUE_TRACKING'),
                                          Node(is_SCHD_expiration_year_8, 'MS_1_PASS', 'CONTINUE_TRACKING'))),
                                Node(is_predicted_crack_above_15_or_rutting_above_04_or_IRI_above_143,
                                     Node(is_AADT_above_15000, 'RR_4INCH_AC_FR_OR_RR_3INCH_AC_FR',
                                          Node(is_AADT_above_3000, 'RR_3INCH_AC_FR',
                                               Node(is_AADT_above_1000, 'RR_2p5INCH_AC_FR', 'RR_2INCH_AC_FR'))),
                                     Node(is_AADT_above_5000,
                                          Node(is_SCHD_expiration_year_8, 'SR_3INCH_AC_MS', 'CONTINUE_TRACKING'),
                                          Node(is_AADT_above_3000,
                                               Node(is_SCHD_expiration_year_9, 'MILL_FR_AND_MICRO_CAPE_SEAL', 'CONTINUE_TRACKING'),
                                               Node(is_SCHD_expiration_year_8, 'CRACKSEAL_AND_CHIPSEAL', 'CONTINUE_TRACKING'))))))),
                 Node(is_interstate,
                      Node(is_crack_under_5,
                           Node(is_rutting_above_01,
                                Node(is_crack_equal_above_2,
                                     Node(is_SCHD_expiration_year_8, 'RR_0p5INCH_FR', 'CONTINUE_TRACKING'),
                                     Node(is_SCHD_expiration_year_9, 'MS_2_PASS', 'CONTINUE_TRACKING')),
                                Node(is_crack_equal_above_2,
                                     Node(is_SCHD_expiration_year_8, 'RR_0p5INCH_FR_OR_MS_1_PASS', 'CONTINUE_TRACKING'),
                                     Node(is_SCHD_expiration_year_3, 'FOG_COAT', 'CONTINUE_TRACKING'))),
                           Node(is_crack_under_8,
                                Node(is_SCHD_expiration_year_8, 'RR_0p5INCH_FR', 'CONTINUE_TRACKING'),
                                Node(is_SCHD_expiration_year_8, 'SR_3INCH_AC_MS', 'CONTINUE_TRACKING'))),
                      Node(is_crack_under_5,
                           Node(is_rutting_above_01,
                                Node(is_crack_equal_above_2,
                                     Node(is_SCHD_expiration_year_8, 'RR_0p5INCH_FR', 'CONTINUE_TRACKING'),
                                     Node(is_SCHD_expiration_year_9, 'MS_2_PASS', 'CONTINUE_TRACKING')),
                                Node(is_crack_equal_above_2,
                                     Node(is_SCHD_expiration_year_8, 'MS_1_PASS_OR_CHIPSEAL', 'CONTINUE_TRACKING'),
                                     Node(is_SCHD_expiration_year_3, 'FOG_COAT', 'CONTINUE_TRACKING'))),
                           Node(is_crack_under_8,
                                Node(is_AADT_above_5000,
                                     Node(is_SCHD_expiration_year_9, 'MILL_FR_AND_MICRO_CAPE_SEAL', 'CONTINUE_TRACKING'),
                                     Node(is_SCHD_expiration_year_7, 'CRACKSEAL_AND_CHIPSEAL', 'CONTINUE_TRACKING')),
                                Node(is_SCHD_expiration_year_8, 'SR_3INCH_AC_MS', 'CONTINUE_TRACKING')))))
            )




#Applying the decision tree
def apply_decision_tree(row, gdf):
    return tree.decide(row)

gdf['Treatment'] = gdf.apply(lambda row: apply_decision_tree(row, gdf), axis=1)

print(gdf[['TARGET_FID', 'PAVEMENT_T', 'Treatment']].head(20))

gdf['New_Rutting'] = gdf['Rutting']
gdf['New_AvgIRI'] = gdf['AvgIRI']
gdf['New_HPMS_Cracking'] = gdf['HPMS_Crack']
gdf['Foundation_Issue'] = 0
gdf['No_of_Rehab'] = np.random.randint(0, 4, size=len(gdf))
gdf['SCHD_Year'] = np.random.randint(0, 10, size=len(gdf))

gdf['Rutting_Hold_Year'] = 0
gdf['Rutting_Recovery_Year'] = 0
gdf['Rutting_Recovery_Year_Updated'] = 0
gdf['Delta_Rutting_Recovery'] = 0.0
gdf['Pre_Treatment_Rutting'] = 0.0

gdf['Crack_Hold_Year'] = 0
gdf['Crack_Recovery_Year'] = 0
gdf['Crack_Recovery_Year_Updated'] = 0
gdf['Delta_Crack_Recovery'] = 0.0
gdf['Pre_Treatment_Crack'] = 0.0
gdf['crack_age'] = gdf['Interpolated_Age']

# Update Number of Rehabilitation where a treatment is being applied
def update_rehabilitation(gdf, treatment_column):
    mask = ~gdf[treatment_column].isin(["DO_NOTHING", "CONTINUE_TRACKING"])
    gdf.loc[mask, 'No_of_Rehab'] += 1


# Update SCHD Year (Scheduled age of treatmen-number of years without applying a treatment)
def update_schd_year(gdf, treatment_column):
    mask = gdf[treatment_column].isin(["DO_NOTHING", "CONTINUE_TRACKING"])
    gdf.loc[mask, 'SCHD_Year'] += 1
    gdf.loc[~mask, 'SCHD_Year'] = 0


# Reset IRI, Crack, Rutting after applying a treatment (Based on Arizona suggestions)
def apply_treatment_resets(gdf, year):
    treatment_column = f'Treatment_Year_{year}'

    # Apply different updates based on treatment types using batch updates
    treatment_masks = {
        'CRACKSEAL': gdf[treatment_column] == 'CRACKSEAL',
        'CRACKSEAL_AND_CHIPSEAL': gdf[treatment_column] == 'CRACKSEAL_AND_CHIPSEAL',
        'MILL_FR_AND_MICRO_CAPE_SEAL': gdf[treatment_column] == 'MILL_FR_AND_MICRO_CAPE_SEAL',
        'MS_1_PASS': gdf[treatment_column] == 'MS_1_PASS',
        'MS_2_PASS': gdf[treatment_column] == 'MS_2_PASS',
        'RECONSTRUCTION': gdf[treatment_column] == 'RECONSTRUCTION',
        'RR_0p5INCH_FR': gdf[treatment_column] == 'RR_0p5INCH_FR',
        'RR_1INCH_FR': gdf[treatment_column] == 'RR_1INCH_FR',
        'RR_2p5INCH_AC_FR': gdf[treatment_column] == 'RR_2p5INCH_AC_FR',
        'RR_3INCH_AC_FR': gdf[treatment_column] == 'RR_3INCH_AC_FR',
        'RR_4INCH_AC_FR': gdf[treatment_column] == 'RR_4INCH_AC_FR',
        'RR_5INCH_AC_FR': gdf[treatment_column] == 'RR_5INCH_AC_FR',
        'SR_3INCH_AC_MS': gdf[treatment_column] == 'SR_3INCH_AC_MS'
    }

    for treatment, mask in treatment_masks.items():
        if mask.any():  # Only process if there are matching rows
            # Perform updates for each treatment type
            if treatment == 'CRACKSEAL':
                #mask = treatment_masks['CRACKSEAL']
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 2
                gdf.loc[mask, 'Crack_Recovery_Year'] = 2
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 2

            elif treatment == 'CRACKSEAL_AND_CHIPSEAL':
                #mask = treatment_masks['CRACKSEAL_AND_CHIPSEAL']
                gdf.loc[mask, 'New_AvgIRI'] *= 1.1
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 2
                gdf.loc[mask, 'Crack_Recovery_Year'] = 4
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 4

            elif treatment == 'MILL_FR_AND_MICRO_CAPE_SEAL':
                #mask = treatment_masks['MILL_FR_AND_MICRO_CAPE_SEAL']
                gdf.loc[mask, 'Pre_Treatment_Rutting'] = gdf.loc[mask, 'New_Rutting']
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'Rutting_Hold_Year'] = 1
                gdf.loc[mask, 'Rutting_Recovery_Year'] = 2
                gdf.loc[mask, 'Rutting_Recovery_Year_Updated'] = 2
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 3
                gdf.loc[mask, 'Crack_Recovery_Year'] = 5
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 5

            elif treatment == 'MS_1_PASS':
                #mask = treatment_masks['MS_1_PASS']
                gdf.loc[mask, 'New_AvgIRI'] *= 0.6
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 2
                gdf.loc[mask, 'Crack_Recovery_Year'] = 4
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 4

            elif treatment == 'MS_2_PASS':
                #mask = treatment_masks['MS_2_PASS']
                gdf.loc[mask, 'New_AvgIRI'] *= 0.6
                gdf.loc[mask, 'Pre_Treatment_Rutting'] = gdf.loc[mask, 'New_Rutting']
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'Rutting_Hold_Year'] = 1
                gdf.loc[mask, 'Rutting_Recovery_Year'] = 2
                gdf.loc[mask, 'Rutting_Recovery_Year_Updated'] = 2
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 2
                gdf.loc[mask, 'Crack_Recovery_Year'] = 5
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 5

            elif treatment == 'RECONSTRUCTION':
                #mask = treatment_masks['RECONSTRUCTION']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'No_of_Rehab'] = 0

            elif treatment == 'FOG_COAT':
                #mask = treatment_masks['FOG_COAT']
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 2
                gdf.loc[mask, 'Crack_Recovery_Year'] = 4
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 4

            elif treatment == 'RR_0p5INCH_FR':
                #mask = treatment_masks['RR_0p5INCH_FR']
                gdf.loc[mask, 'New_AvgIRI'] *= 0.6
                gdf.loc[mask, 'Pre_Treatment_Rutting'] = gdf.loc[mask, 'New_Rutting']
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'Rutting_Hold_Year'] = 1
                gdf.loc[mask, 'Rutting_Recovery_Year'] = 5
                gdf.loc[mask, 'Rutting_Recovery_Year_Updated'] = 5
                gdf.loc[mask, 'Pre_Treatment_Crack'] = gdf.loc[mask, 'New_HPMS_Cracking']
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0
                gdf.loc[mask, 'Crack_Hold_Year'] = 5
                gdf.loc[mask, 'Crack_Recovery_Year'] = 5
                gdf.loc[mask, 'Crack_Recovery_Year_Updated'] = 5

            elif treatment == 'RR_1INCH_FR':
                #mask = treatment_masks['RR_1INCH_FR']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0

            elif treatment == 'RR_2p5INCH_AC_FR':
                #mask = treatment_masks['RR_2p5INCH_AC_FR']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0

            elif treatment == 'RR_3INCH_AC_FR':
                #mask = treatment_masks['RR_3INCH_AC_FR']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0

            elif treatment == 'RR_4INCH_AC_FR':
                #mask = treatment_masks['RR_4INCH_AC_FR']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0

            elif treatment == 'RR_5INCH_AC_FR':
                #mask = treatment_masks['RR_5INCH_AC_FR']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0

            elif treatment == 'SR_3INCH_AC_MS':
                #mask = treatment_masks['SR_3INCH_AC_MS']
                gdf.loc[mask, 'New_AvgIRI'] = 20
                gdf.loc[mask, 'New_Rutting'] = 0
                gdf.loc[mask, 'New_HPMS_Cracking'] = 0

            # Update IRI column immediately
            #gdf.loc[mask, f'AvgIRI_Year_{year}'] = gdf.loc[mask, 'New_AvgIRI']
            #gdf.loc[mask, f'Rutting_Year_{year}'] = gdf.loc[mask, 'New_Rutting']

    return gdf


# Effect of treatment on IRI and Rutting progression (Based on Arizona suggestions)
def apply_treatment_effects(gdf, year):
    treatment_column = f'Treatment_Year_{year-1}'

    # Treatment effects on Rutting
    rutting_hold_mask = gdf['Rutting_Hold_Year'] > 0
    gdf.loc[rutting_hold_mask, 'New_Rutting'] = 0
    gdf.loc[rutting_hold_mask, 'Rutting_Hold_Year'] -= 1

    rutting_recovery_mask = (gdf['Rutting_Hold_Year'] == 0) & (gdf['Rutting_Recovery_Year_Updated'] > 0)
    if rutting_recovery_mask.any():
        rutting_recovery_indices = gdf[rutting_recovery_mask].index
        # Calculate Delta_Rutting_Recovery only at the start of the recovery period
        first_recovery_mask_rutting = gdf['Rutting_Recovery_Year'] == gdf['Rutting_Recovery_Year_Updated']
        first_recovery_indices_rutting = gdf[rutting_recovery_mask & first_recovery_mask_rutting].index
        gdf.loc[first_recovery_indices_rutting, 'Delta_Rutting_Recovery'] = (
            (gdf.loc[first_recovery_indices_rutting, 'Pre_Treatment_Rutting'] -
             gdf.loc[first_recovery_indices_rutting, 'New_Rutting']) /
            gdf.loc[first_recovery_indices_rutting, 'Rutting_Recovery_Year']
        )
        # Apply constant slope during the recovery period
        gdf.loc[rutting_recovery_indices, 'New_Rutting'] += gdf.loc[rutting_recovery_indices, 'Delta_Rutting_Recovery']
        gdf.loc[rutting_recovery_indices, 'Rutting_Recovery_Year_Updated'] -= 1

    # After recovery period, resume normal progression
    post_recovery_mask_rutting = ~rutting_hold_mask & ~rutting_recovery_mask
    gdf.loc[post_recovery_mask_rutting, 'New_Rutting'] += gdf.loc[post_recovery_mask_rutting, 'delta_rutting']



    # Treatment effects on Crack
    crack_hold_mask = gdf['Crack_Hold_Year'] > 0
    gdf.loc[crack_hold_mask, 'New_HPMS_Cracking'] = 0
    gdf.loc[crack_hold_mask, 'Crack_Hold_Year'] -= 1

    crack_recovery_mask = (gdf['Crack_Hold_Year'] == 0) & (gdf['Crack_Recovery_Year_Updated'] > 0)
    if crack_recovery_mask.any():
        crack_recovery_indices = gdf[crack_recovery_mask].index
        # Calculate Delta_Crack_Recovery only at the start of the recovery period
        first_recovery_mask_crack = gdf['Crack_Recovery_Year'] == gdf['Crack_Recovery_Year_Updated']
        first_recovery_indices_crack = gdf[crack_recovery_mask & first_recovery_mask_crack].index
        gdf.loc[first_recovery_indices_crack, 'Delta_Crack_Recovery'] = (
            (gdf.loc[first_recovery_indices_crack, 'Pre_Treatment_Crack'] -
             gdf.loc[first_recovery_indices_crack, 'New_HPMS_Cracking']) /
            gdf.loc[first_recovery_indices_crack, 'Crack_Recovery_Year']
        )
        # Apply constant slope during the recovery period
        gdf.loc[crack_recovery_indices, 'New_HPMS_Cracking'] += gdf.loc[crack_recovery_indices, 'Delta_Crack_Recovery']
        gdf.loc[crack_recovery_indices, 'Crack_Recovery_Year_Updated'] -= 1

    # After recovery period, resume normal progression
    post_recovery_mask_crack = ~crack_hold_mask & ~crack_recovery_mask
    #gdf.loc[post_recovery_mask_crack, 'New_HPMS_Cracking'] += 'YOU SHOULD EDIT THIS PART'

    if post_recovery_mask_crack.any():
        # Filter the necessary columns in one go for efficiency
        subset = gdf.loc[post_recovery_mask_crack, ['crack_age', 'ESAL_20_year', 'Pavement_Family', 'svf', 'New_HPMS_Cracking']]

        # Vectorized calculation of crack progression
        crack_progression = subset.apply(
            lambda row: compute_hpms_crack_projection(
                row['crack_age'], row['ESAL_20_year'], row['Pavement_Family'], row['svf'], row['New_HPMS_Cracking'], years=1
            )[-1], axis=1
        )

        # Efficiently add the new progression to the existing value
        gdf.loc[post_recovery_mask_crack, 'New_HPMS_Cracking'] = crack_progression

        # Vectorized increment of crack_age
        gdf.loc[post_recovery_mask_crack, 'crack_age'] += 1


    # Apply treatment effects on IRI
    gdf.loc[:, 'New_AvgIRI'] += gdf.loc[:, 'delta_iri']

    # Update values immediately in the dataframe
    #gdf.loc[:, f'AvgIRI_Year_{year}'] = gdf['New_AvgIRI']
    #gdf.loc[:, f'Rutting_Year_{year}'] = gdf['New_Rutting']

    return gdf


# Helper function to replace `_OR_` treatments with the highest GHG emission
def replace_or_treatment(treatment, treatment_table):
    if '_OR_' in treatment:
        treatments = treatment.split('_OR_')
        # Find the treatment with the highest emission
        max_treatment = max(
            treatments, key=lambda t: treatment_table.at[t, 'Total'] if t in treatment_table.index else float('-inf')
        )
        return max_treatment
    return treatment

#yearly_budgets = {year: 320000000 for year in range(31)}
years = 32
yearly_budgets = np.full(years, 320000000)


def apply_budget_constraint(gdf, year, budget, treatments, pre_reset_iri):
    treatment_col = f'Treatment_Year_{year}'

    # Compute cost per section based on lane miles
    gdf['Section_Cost'] =  gdf[treatment_col].map(lambda t: float(treatments.get(t, {}).get('Cost_lane_mi', 0))) * ((gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_'])

    # Convert the NumPy array to a pandas Series for sorting
    pre_reset_series = pd.Series(pre_reset_iri[year], index=gdf.index)
    # Sort the Series in descending order and get the sorted index
    sorted_index = pre_reset_series.sort_values(ascending=False).index
    # Use the sorted index to reorder gdf
    gdf_sorted = gdf.loc[sorted_index]

    # Sort by highest IRI before treatment using pre-reset values
    #gdf_sorted = gdf.loc[pre_reset_iri.sort_values(ascending=False).index]

    # Allocate budget iteratively
    total_cost = 0
    selected_indices = []

    for idx, row in gdf_sorted.iterrows():
        section_cost = row['Section_Cost']
        if total_cost + section_cost <= budget:
            total_cost += section_cost
            selected_indices.append(idx)
        else:
            break

    # Update treatments based on budget allocation
    gdf.loc[~gdf.index.isin(selected_indices), treatment_col] = "DO_NOTHING"

    # Drop auxiliary column
    gdf.drop(columns=['Section_Cost'], inplace=True)

    return gdf

# Apply decision tree for several years (updates Number of Rehabilitation, SCHD Year, effect of applying treatments on IRI, Rutting, Crack progression )
def apply_decision_tree_for_years(gdf, years=20):

    # Filter rows with 'PAVEMENT_T' == 'AC'
    ac_mask = gdf['PAVEMENT_T'] == 'AC'

    gdf['No_of_Rehab'] = np.random.randint(0, 4, size=len(gdf))
    gdf['SCHD_Year'] = np.random.randint(0, 10, size=len(gdf))
    gdf['New_Rutting'] = gdf['Rutting']
    gdf['New_HPMS_Cracking'] = gdf['HPMS_Crack']
    gdf['New_AvgIRI'] = gdf['AvgIRI']
    new_columns = {}
    pre_reset_iri = {}

    # Apply the initial treatment (year 0)
    #treatment_cols = [f'Treatment_Year_0']  # Start with year 0
    gdf['Treatment_Year_0'] = gdf.apply(lambda row: apply_decision_tree(row, gdf), axis=1)
    gdf['Treatment_Year_0'] = gdf['Treatment_Year_0'].apply(lambda treatment: replace_or_treatment(treatment, Treatment_Table))

    # Save New_AvgIRI before resetting for year 0
    pre_reset_iri[0] = gdf['New_AvgIRI'].values.copy()

    # Apply budget constraint
    gdf = apply_budget_constraint(gdf, 0, yearly_budgets[0], treatments, pre_reset_iri[0])

    # Update Number of Rehabilitation and treatment resets
    update_rehabilitation(gdf, 'Treatment_Year_0')
    gdf = apply_treatment_resets(gdf, 0)

    # Pre-allocate arrays for new columns
    rutting_array = np.zeros((len(gdf), years + 1), dtype=np.float32)
    crack_array = np.zeros((len(gdf), years + 1), dtype=np.float32)
    avg_iri_array = np.zeros((len(gdf), years + 1), dtype=np.float32)


    # Initialize the first year values
    rutting_array[:, 0] = gdf['New_Rutting'].values
    crack_array[:, 0] = gdf['New_HPMS_Cracking'].values
    avg_iri_array[:, 0] = gdf['New_AvgIRI'].values

    # Iterate over each year and apply updates
    for year in range(1, years + 1):
        treatment_col = f'Treatment_Year_{year}'
        #treatment_cols.append(treatment_col)
        gdf = apply_treatment_effects(gdf, year)
        gdf[treatment_col] = gdf.apply(lambda row: apply_decision_tree(row, gdf), axis=1)
        gdf[treatment_col] = gdf[treatment_col].apply(lambda treatment: replace_or_treatment(treatment, Treatment_Table))

        # Save New_AvgIRI before resetting for this year
        pre_reset_iri[year] = gdf['New_AvgIRI'].values.copy()

        # Apply budget constraint for the year
        gdf = apply_budget_constraint(gdf, year, yearly_budgets[year], treatments, pre_reset_iri[year])

        gdf = apply_treatment_resets(gdf, year)
        update_rehabilitation(gdf, treatment_col)
        update_schd_year(gdf, treatment_col)

        # Store the new values in the pre-allocated arrays
        rutting_array[:, year] = gdf['New_Rutting'].values
        crack_array[:, year] = gdf['New_HPMS_Cracking'].values
        avg_iri_array[:, year] = gdf['New_AvgIRI'].values


    # Convert the arrays into a DataFrame with appropriate column names
    rutting_columns = {f'Rutting_Year_{i}': rutting_array[:, i] for i in range(0, years + 1)}
    crack_columns = {f'Crack_Year_{i}': crack_array[:, i] for i in range(0, years + 1)}
    avg_iri_columns = {f'AvgIRI_Year_{i}': avg_iri_array[:, i] for i in range(0, years + 1)}

    # Add the new columns to the original DataFrame
    gdf = pd.concat([gdf, pd.DataFrame(rutting_columns, index=gdf.index),
                     pd.DataFrame(crack_columns, index=gdf.index),
                     pd.DataFrame(avg_iri_columns, index=gdf.index)], axis=1)

    # Identify duplicate columns
    #duplicate_columns = gdf.columns[gdf.columns.duplicated()].unique()

    # Drop the first occurrence of each duplicate column, keeping the last (most updated)
    #for col in duplicate_columns:
     #   gdf = gdf.loc[:, ~gdf.columns.duplicated(keep='last')]

    return gdf




gdf = apply_decision_tree_for_years(gdf, years=31)

print(gdf[['TARGET_FID', 'PAVEMENT_T', 'Treatment_Year_0', 'Treatment_Year_1', 'Treatment_Year_2', 'Treatment_Year_3','Treatment_Year_4','Treatment_Year_5', 'Treatment_Year_6', 'Treatment_Year_7', 'Treatment_Year_8', 'Treatment_Year_9', 'Treatment_Year_10', ]].head(20))

print(gdf[['Interpolated_Age', 'crack_age', 'HPMS_Crack', 'New_HPMS_Cracking', 'Rutting_Year_0', 'Crack_Year_0', 'Crack_Year_1', 'Crack_Year_2', 'Crack_Year_3', 'Crack_Year_4', 'Crack_Year_5', 'AvgIRI_Year_0', 'AvgIRI_Year_1', 'AvgIRI_Year_2', 'AvgIRI_Year_3', 'AvgIRI_Year_4', 'AvgIRI_Year_5']].head(30))

print("Final columns in gdf:", gdf.columns.tolist())

import pandas as pd
import matplotlib.pyplot as plt
'''
def plot_table(treatments_gdf):
    # Select the relevant columns and the first 100 rows
    columns_to_display = [
        'PAVEMENT_T', 'HPMS_Crack', 'Crack_Year_0', 'Crack_Year_1', 'Crack_Year_2', 'Crack_Year_3', 'Crack_Year_4',
        'Rutting', 'Rutting_Year_0', 'Rutting_Year_1', 'Rutting_Year_2', 'Rutting_Year_3', 'Rutting_Year_4',
        'AvgIRI','AvgIRI_Year_0', 'AvgIRI_Year_1', 'AvgIRI_Year_2', 'AvgIRI_Year_3', 'AvgIRI_Year_4',
        'Treatment_Year_0', 'Treatment_Year_1', 'Treatment_Year_2', 'Treatment_Year_3','Treatment_Year_4',
    ]
    data_to_display = treatments_gdf[columns_to_display].head(1000)

    # Plot the table
    fig, ax = plt.subplots(figsize=(60, 8))
    ax.axis('off')
    table = ax.table(cellText=data_to_display.values, colLabels=data_to_display.columns, loc='center')
    table.scale(1, 1.5)
    table.auto_set_font_size(False)
    table.set_fontsize(8)

    plt.show()

plot_table(treatments_gdf)
'''

import pandas as pd
import matplotlib.pyplot as plt
'''
def plot_table(treatments_gdf):
    # Filter the rows where 'AvgIRI' is 0 or None
    filtered_gdf = treatments_gdf[(treatments_gdf['AvgIRI'] != 0) | (treatments_gdf['AvgIRI'].isna())]

    # Select the relevant columns and the first 100 rows
    columns_to_display = [ 'PAVEMENT_T',
        'Interpolated_Age', 'crack_age', 'HPMS_Crack', 'Rutting', 'Rutting_Year_2',
        'AvgIRI_Year_0', 'AvgIRI_Year_1', 'AvgIRI_Year_2', 'AvgIRI_Year_3', 'AvgIRI_Year_4', 'AvgIRI_Year_5', 'AvgIRI_Year_6', 'AvgIRI_Year_7', 'AvgIRI_Year_8',
    ]
    data_to_display = filtered_gdf[columns_to_display].head(100)

    # Plot the table
    fig, ax = plt.subplots(figsize=(40, 8))
    ax.axis('off')
    table = ax.table(cellText=data_to_display.values, colLabels=data_to_display.columns, loc='center')
    table.scale(1, 1.5)
    table.auto_set_font_size(False)
    table.set_fontsize(8)

    plt.show()

plot_table(treatments_gdf)
'''

print(gdf[['Rutting_Year_0', 'Rutting_Year_1', 'Rutting_Year_2', 'Rutting_Year_3', 'Rutting_Year_4', 'Rutting_Year_5', 'AvgIRI_Year_0', 'AvgIRI_Year_1', 'AvgIRI_Year_2', 'AvgIRI_Year_3', 'AvgIRI_Year_4', 'AvgIRI_Year_5']].head(30))



import matplotlib.pyplot as plt



'''
columns = [
    'TARGET_FID', 'PAVEMENT_T', 'Treatment_Year_0', 'Treatment_Year_1', 'Treatment_Year_2', 'Treatment_Year_3', 'Crack_Year_0', 'Crack_Year_1', 'Crack_Year_2', 'Crack_Year_3'
]
treatment_to_plot = treatments_gdf.head(1000)[columns]

for col in [ 'Crack_Year_0', 'Crack_Year_1', 'Crack_Year_2', 'Crack_Year_3']:
    treatment_to_plot[col] = treatment_to_plot[col].apply(lambda x: f"{x:.4f}")


fig, ax = plt.subplots(figsize=(15, 10))
ax.axis('tight')
ax.axis('off')

table = ax.table(
    cellText=treatment_to_plot.values,
    colLabels=treatment_to_plot.columns,
    cellLoc='center',
    loc='center'
)

table.auto_set_font_size(False)
table.set_fontsize(9)
table.auto_set_column_width(col=list(range(len(columns))))

plt.show()
'''



vehicle_names = {
    'Passenger Vehicle': 'PV',
    'Small Truck': 'ST',
    'Medium Truck': 'MT',
    'Large Truck': 'LT'
}
#MJ per gallon
fuel_conversion_rates = {
    'Passenger Vehicle': 126.3,
    'Small Truck': 126.3,
    'Medium Truck': 145,
    'Large Truck': 145
}
co2_emission_factors = {
    'Passenger Vehicle': 10.8393, # add 1.9523 (GREET) #gasoline
    'Small Truck':10.8393, #add 1.9523 (GREET) #gasoline
    'Medium Truck': 11.8169, #add 1.6369 (GREET) #diesel
    'Large Truck': 11.8169, #add 1.6369 (GREET) #diesel
}
energy_coefficients = {
    'Passenger Vehicle': {'ka': 0.67, 'kc': 0.000281, 'dc': 0.2186, 'da': 2175.7, 'b': -16.931, 'p': 33753},
    'Small Truck': {'ka': 0.768, 'kc': 0.000125, 'dc': 0.30769, 'da': 7010.8, 'b': -73.026, 'p': 117880},
    'Medium Truck': {'ka': 0.918, 'kc': 0.000133, 'dc': 0.97418, 'da': 9299.3, 'b': -139.58, 'p': 109380},
    'Large Truck': {'ka': 1.4, 'kc': 0.000136, 'dc': 2.39, 'da': 19225, 'b': -264.32, 'p': 82782}
}
#assumption can be changed
vehicle_percentages = {
    'Passenger Vehicle': 0.70,
    'Small Truck': 0.10,
    'Medium Truck': 0.15,
    'Large Truck': 0.05
}
# Define the coefficients for IRI based on Pavement Family (ArizonaDOT)
base_coefficients = {
    '11': {'IRI': {'a': 0.254, 'b': 0, 'c': 3.73}},
    '12': {'IRI': {'a': 0.272, 'b': 0, 'c': 1.57}},
    '21': {'IRI': {'a': 0, 'b': 0.3, 'c': 3.6}},
    '22': {'IRI': {'a': 0, 'b': 0.3, 'c': 3.6}},
    '1141': {'IRI': {'a': 0.254, 'b': 0, 'c': 3.73}},
}

avg_iri_previous = gdf['AvgIRI']

for year in range(0, 31):
    avg_iri_column = f'AvgIRI_Year_{year}'
    iri_after_column = f'AvgIRI_Year_{year+1}'

    if year == 0:
        # For year 0, calculate avg_iri_column as the average of gdf['AvgIRI'] and AvgIRI_Year_0
        gdf[avg_iri_column] = (avg_iri_previous + gdf[avg_iri_column]) / 2
    else:

        gdf[avg_iri_column] = (avg_iri_previous + gdf[iri_after_column]) / 2

    avg_iri_previous = gdf[avg_iri_column]

# Energy and CO2 Emission Calculation
base_iri = 20  # in/mile

def calculate_differential_energy(avg_iri_column, vehicle_type, base_iri=20):
    coeffs = energy_coefficients[vehicle_type]
    speed = gdf['AVERAGE_SP']

    # Extract coefficients
    ka = coeffs['ka']
    kc = coeffs['kc']
    dc = coeffs['dc']
    da = coeffs['da']
    b = coeffs['b']
    p = coeffs['p']

    # Compute energy_base
    energy_base = (
        (p / speed) +
        (ka * base_iri + da) +
        (b * speed) +
        ((kc * base_iri) + dc) * (speed ** 2)
    ) / 1000  # Convert kJ to MJ

    # Compute energy_actual using `gdf[avg_iri_column]`
    energy_actual = (
        (p / speed) +
        (ka * gdf[avg_iri_column] + da) +
        (b * speed) +
        ((kc * gdf[avg_iri_column]) + dc) * (speed ** 2)
    ) / 1000  # Convert kJ to MJ

    return energy_actual - energy_base  # Differential energy


# Initialize AADT values with growth for each year
annual_traffic_growth = 0.00001  # 2% growth rate

# Initialize the base AADT for the first year
gdf['AADT_Year_1'] = gdf['AADT']  # AADT from ArcGIS data

# Calculate AADT for subsequent years
for year in range(2, 32):
    gdf[f'AADT_Year_{year}'] = gdf[f'AADT_Year_{year - 1}'] * (1 + annual_traffic_growth)

# Shortened vehicle type names
vehicle_names = {
    'Passenger Vehicle': 'PV',
    'Small Truck': 'ST',
    'Medium Truck': 'MT',
    'Large Truck': 'LT'
}

for year in range(0, 31):
    avg_iri_column = f'AvgIRI_Year_{year}'
    aadt_column = f'AADT_Year_{year+1}'
    co2_columns_this_year = []

    for vehicle, short_name in vehicle_names.items():
        vehicle_percentage = vehicle_percentages[vehicle]
        fuel_mj_per_gal = fuel_conversion_rates[vehicle]
        co2_factor = co2_emission_factors[vehicle]
        co2_column = f'CO2_{short_name}_{year}year'

        differential_energy = calculate_differential_energy(avg_iri_column, vehicle)

        condition = differential_energy > 0

        # Compute CO2 emissions only where condition is True, else 0
        gdf[co2_column] = np.where(
            condition,
            differential_energy / fuel_mj_per_gal * co2_factor * gdf[aadt_column] * vehicle_percentage * (gdf['ToMeasure'] - gdf['FromMeasur']) * 365 / 1e9,
            0
        )

        co2_columns_this_year.append(co2_column)

    # Total CO2 for this year from all vehicles
    gdf[f'total_CO2_{year}year'] = gdf[co2_columns_this_year].sum(axis=1)



# A dictionary to store the total CO₂ emissions per year for each vehicle type
yearly_co2_totals = {year: {} for year in range(0, 31)}

vehicle_names = {
    'PV': 'Passenger Vehicle',
    'ST': 'Small Truck',
    'MT': 'Medium Truck',
    'LT': 'Large Truck'
}

# Loop through each year and each vehicle type to calculate total CO₂ emissions
for year in range(0, 31):
    total_emission_sum = 0  # Initialize total emission sum for the year
    for short_name, full_name in vehicle_names.items():
        co2_column = f'CO2_{short_name}_{year}year'

        # Check if the column exists before summing
        if co2_column in gdf.columns:
            total_emission =gdf[co2_column].sum()
        else:
            total_emission = 0  # Default to 0 if the column is missing

        yearly_co2_totals[year][full_name] = total_emission
        total_emission_sum += total_emission  # Add to the total emission sum

    # Store the total emissions for all vehicles in the year
    yearly_co2_totals[year]['Total Emissions'] = total_emission_sum

# Display the total CO₂ emissions for each year and vehicle type
for year, co2_totals in yearly_co2_totals.items():
    print(f"\nTotal CO₂ emissions (pump to wheel) for Year {year}:")
    for vehicle, total_emission in co2_totals.items():
        print(f"{vehicle}: {total_emission:.2f} MMT kgCO2")



import matplotlib.pyplot as plt
import numpy as np

# Extract data for visualization from the yearly_co2_totals dictionary
years = list(range(0, 31))  # Years 1 to 30
vehicle_types = ['Passenger Vehicle', 'Small Truck', 'Medium Truck', 'Large Truck']
colors = ['blue', 'green', 'red', 'purple']

# Prepare data for stacking
emissions_data = {vehicle: [] for vehicle in vehicle_types}
for year in years:
    for vehicle in vehicle_types:
        emissions_data[vehicle].append(yearly_co2_totals[year].get(vehicle, 0))

# Convert to NumPy arrays for easier manipulation
emissions_data_np = np.array([emissions_data[vehicle] for vehicle in vehicle_types])

# Initialize the bottom positions for the stacked bars
bottom = np.zeros(len(years))

# Create the figure and axis objects
fig, ax = plt.subplots(figsize=(14, 8))

# Plot each vehicle type's emissions as a stacked bar
for idx, (vehicle, color) in enumerate(zip(vehicle_types, colors)):
    ax.bar(years, emissions_data_np[idx], bottom=bottom, color=color, label=vehicle)
    bottom += emissions_data_np[idx]  # Update the bottom for stacking

# Set labels and title
ax.set_xlabel('Years')
ax.set_ylabel('Total MMT CO₂ Emissions')
ax.set_title('Total CO₂ Emissions by Vehicle Type (Pump to Wheel)')

# Set x-ticks for every year
ax.set_xticks(years)
ax.set_xticklabels(years, rotation=0)

ax.set_ylim(0, 0.7)
ax.set_yticks(np.arange(0, 0.8, 0.1))

# Add a legend to identify vehicle types
ax.legend(loc='upper left', fontsize='large', frameon=True, bbox_to_anchor=(0.1, 0.98))

# Add grid lines for clarity
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Adjust layout for a clean appearance
plt.tight_layout()

# Display the plot
plt.show()

print(gdf[['AvgIRI']].mean())

for year in range(30):
    column = f'AvgIRI_Year_{year}'
    if column in gdf.columns:
        mean_value = gdf[column].mean()
        print(f"{column} = {mean_value:.2f}")
print(gdf[['AvgIRI']].head(30))

# Compute the calculated lane miles only once for efficiency
gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']
gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']

# Compute the weighted average of the original AvgIRI column
total_lane_miles = gdf['Calculated_Lane_Miles'].sum()
weighted_avgiri = (gdf['AvgIRI'] * gdf['Calculated_Lane_Miles']).sum() / total_lane_miles if total_lane_miles > 0 else 0
print(f"Weighted AvgIRI = {weighted_avgiri:.2f}")

# Compute weighted means for all years in a vectorized way
years = []
weighted_avg_iri = []

for year in range(31):
    column = f'AvgIRI_Year_{year}'
    if column in gdf.columns:
        total_treatment_lane_miles = gdf['Calculated_Lane_Miles'].sum()
        weighted_mean = (gdf[column] * gdf['Calculated_Lane_Miles']).sum() / total_treatment_lane_miles if total_treatment_lane_miles > 0 else 0
        print(f"{column} = {weighted_mean:.2f}")
        years.append(year)
        weighted_avg_iri.append(weighted_mean)

# ✅ Print first 30 rows of AvgIRI
print(gdf[['AvgIRI']].head(30))

# ✅ Plot the weighted AvgIRI over time
plt.figure(figsize=(10, 5))
plt.plot(years, weighted_avg_iri, marker='o', linestyle='-', label="Weighted AvgIRI")
plt.xlabel("Year")
plt.ylabel("Weighted Average IRI")
plt.ylim(40, 180)
plt.yticks(np.arange(40, 190, 10))
plt.title("Weighted AvgIRI Progression Over Time")
plt.legend()
plt.grid(True)
plt.show()

#gdf = apply_decision_tree_for_years(gdf, years=30)
#print(gdf[['Rutting_Year_0', 'Rutting_Year_1', 'Rutting_Year_2', 'Rutting_Year_3', 'Rutting_Year_4', 'Rutting_Year_5', 'AvgIRI_Year_0', 'AvgIRI_Year_1', 'AvgIRI_Year_2', 'AvgIRI_Year_3', 'AvgIRI_Year_4', 'AvgIRI_Year_5']].head(20))



treatments = import_draft_treatments(path)

for treatment_name, treatment_data in treatments.items():
    cost_lane_mi = treatment_data.get('Cost_lane_mi')
    print(f"Treatment: {treatment_name}, Cost_lane_mi: {cost_lane_mi}")

Treatment_Table.columns

import numpy as np

# Extract cost per lane mile dynamically from treatments dataset
treatment_costs = {
    treatment_name: treatment_data.get('Cost_lane_mi', 0) or 0
    for treatment_name, treatment_data in treatments.items()
}

# Precompute the treatment costs as a Series for faster lookups
treatment_costs_series = pd.Series(treatment_costs)

# Initialize arrays to store costs
annual_cost_totals = {f'Year_{year}': 0 for year in range(31)}  # Initialize totals for each year
cost_arrays = np.zeros((len(gdf), 31))  # Preallocate a NumPy array for segment costs

# Iterate over each year to calculate the costs
for year in range(31):
    treatment_column = f'Treatment_Year_{year}'

    # Map treatment names to costs using the precomputed Series and multiply by lane miles
    gdf[f'Cost_Year_{year}'] = (
        gdf[treatment_column].map(treatment_costs_series).fillna(0) * ((gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_'])
    )

    # Store per-segment costs in the preallocated array
    cost_arrays[:, year] = gdf[f'Cost_Year_{year}']

    # Sum the total costs for the year
    annual_cost_totals[f'Year_{year}'] = cost_arrays[:, year].sum()

# Convert the annual costs to a DataFrame for easier analysis
total_annual_costs_df = pd.DataFrame.from_dict(
    annual_cost_totals, orient='index', columns=['Total_Annual_Cost']
)

# Print or return the total annual costs and updated gdf
print(total_annual_costs_df)

import matplotlib.pyplot as plt
import numpy as np

# Extract years and costs from the total_annual_costs_df
years = total_annual_costs_df.index.str.extract(r'Year_(\d+)')[0].astype(int)  # Extract numeric years
total_costs = total_annual_costs_df['Total_Annual_Cost']

# Plot the total annual costs as a bar chart
plt.figure(figsize=(12, 6))
plt.bar(years, total_costs, color='skyblue', edgecolor='black')

# Add labels and title
#plt.title('Total Annual Treatment Costs Over 30 Years', fontsize=16)
plt.xlabel('Year', fontsize=14)
plt.ylabel('Total Cost ($)', fontsize=14)
plt.xticks(years)  # Show all years on the x-axis
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Display the plot
plt.tight_layout()
plt.show()

import pandas as pd
import warnings

def sum_emissions_by_stage(gdf, Treatment_Table, years=31):
    """
    Function to calculate total emissions (A1 to C2) for each year (Treatment_Year_0 to Treatment_Year_{years})
    across all pavement segments using vectorized operations.

    :param gdf: DataFrame containing pavement segments and their treatments across years.
    :param treatment_table: DataFrame containing GHG emissions for each treatment and stage (A1 to C2).
    :param years: The number of years to consider (default 30).
    :return: A dictionary with summed emissions for each stage (A1 to C2) by year.
    """
    # Initialize dictionary to store emissions for each year and stage
    yearly_emissions = {year: {'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'C2': 0, 'Total': 0} for year in range(years + 1)}
    total_emissions = {'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0, 'C2': 0, 'Total': 0}

    # Conversion factors
    yards_to_mile = 1760  # Converts 1 yard to 1 mile length (1 mile = 1760 yards)
    yards_to_feet = 1 / 3  # Converts 1 yard to 1 foot length (3 feet = 1 yard)

    # Calculate the conversion factor once for all lane widths
    conversion_factor = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_'] * gdf['LaneWidth'] * yards_to_feet * yards_to_mile
    gdf['Calculated_Lane_Miles'] = conversion_factor

    # Initialize new columns in gdf for each year's emissions
    for year in range(years + 1):
        gdf[f'MR_Emission_Year_{year}'] = 0  # Initialize all emission columns to 0

    # Loop over each year to apply vectorized calculations
    for year in range(0, years + 1):
        treatment_col = f'Treatment_Year_{year}'

        # Check for unmatched treatments and raise warnings, excluding 'DO_NOTHING' and 'CONTINUE_TRACKING'
        excluded_treatments = ["DO_NOTHING", "CONTINUE_TRACKING", "REPAIR"]
        unmatched_treatments = gdf[
            ~gdf[treatment_col].isin(Treatment_Table.index) &
            ~gdf[treatment_col].isin(excluded_treatments)
        ][treatment_col]

        # Raise warnings for unmatched treatments
        for unmatched in unmatched_treatments.unique():
            warnings.warn(f"Warning: Treatment '{unmatched}' is not found in Treatment_Table.")

        # Filter treatments and emissions for rows with valid treatments in the current year
        valid_treatments = gdf[treatment_col].isin(Treatment_Table.index)

        # If no valid treatments in this year, skip to the next year
        if valid_treatments.sum() == 0:
            continue

        # Select only valid rows for current year
        selected_treatments = gdf.loc[valid_treatments, treatment_col]
        selected_conversion = conversion_factor[valid_treatments]

        # Initialize the yearly total emissions for this year
        yearly_total = 0

        # Calculate emissions for each section (not the total)
        section_emissions = []

        # Map treatment emissions from the treatment table and multiply by the conversion factor
        for stage in ['A1', 'A2', 'A3', 'A4', 'A5', 'C2']:
            # Retrieve emission values for each treatment in this stage
            emissions = selected_treatments.map(Treatment_Table[stage])
            # Sum of emissions for the current stage and year after scaling with conversion
            yearly_emissions[year][stage] = (emissions * selected_conversion).sum()
            # Add to total emissions across all years
            total_emissions[stage] += yearly_emissions[year][stage]
            # Accumulate yearly total for this year
            yearly_total += yearly_emissions[year][stage]

            # Store emissions for each section (per section emissions)
            section_emissions.append(emissions * selected_conversion)

        # Store the total for the current year
        yearly_emissions[year]['Total'] = yearly_total
        # Add to the grand total
        total_emissions['Total'] += yearly_total

        # Calculate and store emissions for each section for the current year
        gdf[f'MR_Emission_Year_{year}'] = pd.concat(section_emissions, axis=1).sum(axis=1)
        gdf[f'MR_Emission_Year_{year}'] = gdf[f'MR_Emission_Year_{year}'].fillna(0)

    return yearly_emissions, total_emissions

# Call the function
yearly_emissions, total_emissions = sum_emissions_by_stage(gdf, Treatment_Table, years=30)

# Output the summed emissions for each year and stage
for year, emissions in yearly_emissions.items():
    print(f"Emissions for Treatment_Year_{year}:")
    for stage, total in emissions.items():
        print(f"  {stage}: {total / 1e9:.6f} MMT CO2-eq")
    print()

# Output the cumulative summed emissions across all years
print("Summed Emissions by Stage (A1 to C2) for all years:")
for stage, total in total_emissions.items():
    print(f"{stage}: {total / 1e9:.6f} MMT CO2-eq")

import matplotlib.pyplot as plt

# Assuming yearly_emissions contains data for each year from 0 to 29
years = list(yearly_emissions.keys())[:30]  # Original range: 0-29
adjusted_years = [year + 1 for year in years]  # Adjusted range: 1-30

# Extract total emissions per year and convert to MMT
total_emissions_per_year = [yearly_emissions[year]['Total'] / 1e9 for year in years]  # Convert to MMT

# Set the style to default (white background)
plt.style.use('default')

# Plot the total CO₂ emissions per year with adjusted year labels
plt.figure(figsize=(10, 6))
plt.bar(adjusted_years, total_emissions_per_year, color='teal', edgecolor='black', width=0.7)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.xlabel("Year")
plt.ylabel("CO₂-equiv (MMT)")

#plt.xticks(adjusted_years)  # Ensure x-ticks match the adjusted labels
plt.xticks([1, 5, 10, 15, 20, 25, 30])

plt.ylim(0, 0.9)
plt.yticks(np.arange(0, 1, 0.1))

plt.show()

# Plot each stage (A1 to C2) and total for each year
stages = ['A1', 'A2', 'A3', 'A4', 'A5', 'C2', 'Total']
stage_emissions = {stage: [yearly_emissions[year][stage] / 1e9 for year in years] for stage in stages}  # Convert to MMT

plt.figure(figsize=(12, 8))
for stage in stages:
    plt.plot(adjusted_years, stage_emissions[stage], label=stage, marker='o')

plt.xlabel("Year")
plt.ylabel("CO₂ Equivalent (MMT)")
plt.title("CO₂ Emissions by Stage and Total per Year")
plt.legend()
plt.xticks(adjusted_years)  # Ensure x-ticks match the adjusted labels
plt.ylim(0, 0.9)
plt.yticks(np.arange(0, 1, 0.1))
plt.show()

import matplotlib.pyplot as plt

# Assuming yearly_emissions contains data for each year from 0 to 29
years = list(yearly_emissions.keys())[:31]  # Original range: 0-29
adjusted_years = [year + 1 for year in years]  # Adjusted range: 1-30

# Extract total emissions per year and convert to MMT
total_emissions_per_year = [yearly_emissions[year]['Total'] / 1e9 for year in years]  # Convert to MMT

# Set the style to default (white background)
plt.style.use('default')

# Plot the total CO₂ emissions per year with adjusted year labels
plt.figure(figsize=(10, 6))
plt.bar(years, total_emissions_per_year, color='teal', edgecolor='black', width=0.7)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.xlabel("Year")
plt.ylabel("CO₂-equiv (MMT)")

#plt.xticks(adjusted_years)  # Ensure x-ticks match the adjusted labels
plt.xticks(rotation=0)

plt.ylim(0, 0.9)
plt.yticks(np.arange(0, 1, 0.1))

plt.show()


# Plot each stage (A1 to C2) and total for each year
stages = ['A1', 'A2', 'A3', 'A4', 'A5', 'C2', 'Total']
stage_emissions = {stage: [yearly_emissions[year][stage] / 1e9 for year in years] for stage in stages}  # Convert to MMT

plt.figure(figsize=(12, 8))
for stage in stages:
    plt.plot(years, stage_emissions[stage], label=stage, marker='o')

plt.xlabel("Year")
plt.ylabel("CO₂ Equivalent (MMT)")
plt.title("CO₂ Emissions by Stage and Total per Year")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend()
plt.xticks(years)  # Ensure x-ticks match the adjusted labels

plt.ylim(0, 0.9)
plt.yticks(np.arange(0, 1, 0.1))
plt.show()

print("Keys in yearly_emissions:", list(yearly_emissions.keys()))

import pandas as pd

def applied_treatment_percentage_weighted(gdf, years=30):

    # List of excluded treatments
    excluded_treatments = ["DO_NOTHING", "CONTINUE_TRACKING", "REPAIR"]

    # Initialize a dictionary to store the percentages
    treatment_percentages = {}
    treatment_lanemiles = {}

    gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']

    for year in range(years + 1):
        treatment_col = f'Treatment_Year_{year}'

        # Total lane miles for this year
        total_lane_miles = gdf['Calculated_Lane_Miles'].sum()

        # Lane miles for treatments not in the excluded list
        treatment_lane_miles = gdf.loc[~gdf[treatment_col].isin(excluded_treatments), 'Calculated_Lane_Miles'].sum()

        # Calculate the percentage (weighted by Lane_Miles)
        percentage = (treatment_lane_miles / total_lane_miles) * 100 if total_lane_miles > 0 else 0

        # Store the result
        treatment_percentages[f'{year}'] = percentage
        treatment_lanemiles[f'{year}'] = treatment_lane_miles

    # Convert to a DataFrame for easier visualization
    percentage_df = pd.DataFrame.from_dict(treatment_percentages, orient='index', columns=['Percentage'])
    percentage_df.index.name = 'Year'
    lanemile_df = pd.DataFrame.from_dict(treatment_lanemiles, orient='index', columns=['Treatmen_LaneMiles'])
    lanemile_df.index.name = 'Year'

    return percentage_df, lanemile_df

# Calculate the percentages
applied_treatment_percentage_weighted = applied_treatment_percentage_weighted(gdf, years=30)

# Display the results
print(applied_treatment_percentage_weighted)

import matplotlib.pyplot as plt

# Unpack the results into two DataFrames
percentage_df, lanemile_df = applied_treatment_percentage_weighted

# Plot 1: Percentage of Applied Treatments by Year
plt.figure(figsize=(12, 6))
plt.bar(percentage_df.index, percentage_df['Percentage'], color='lightblue', edgecolor='black')
plt.title('Percentage of Applied Treatments by Year (Weighted by Lane Miles)', fontsize=14)
plt.xlabel('Year', fontsize=12)
plt.ylabel('Percentage (%)', fontsize=12)
plt.xticks()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.ylim(0, 60)
plt.yticks(np.arange(0, 60, 10))
plt.tight_layout()
plt.show()

# Plot 2: Lane Miles of Applied Treatments by Year
plt.figure(figsize=(12, 6))
plt.bar(lanemile_df.index, lanemile_df['Treatmen_LaneMiles'], color='orange', edgecolor='black')
plt.title('Lane Miles of Applied Treatments by Year', fontsize=14)
plt.xlabel('Year', fontsize=12)
plt.ylabel('Lane Miles', fontsize=12)
plt.xticks()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Initialize a dictionary to store the percentage of "DO_NOTHING" or "CONTINUE_TRACKING" for each year
percentage_tracking_by_year = {}

# Loop through each year and calculate the percentage
for year in range(len(yearly_emissions)):  # Adjust this range based on the maximum number of years you're tracking
    treatment_column = f'Treatment_Year_{year}'

    # Calculate the number of segments with "DO_NOTHING" or "CONTINUE_TRACKING" for the current year
    tracking_mask = gdf[treatment_column].isin(["DO_NOTHING", "CONTINUE_TRACKING", "REPAIR"])
    tracking_count = tracking_mask.sum()

    # Calculate the percentages
    total_segments = len(gdf)
    tracking_percentage = (tracking_count / total_segments) * 100
    applied_treatment_percentage = 100 - tracking_percentage

    # Store the result in the dictionary
    percentage_tracking_by_year[treatment_column] = (tracking_percentage, applied_treatment_percentage)

# Display the percentages
for year, (tracking_percentage, applied_treatment_percentage) in percentage_tracking_by_year.items():
    print(f"{year}: {applied_treatment_percentage:.2f}%")

import matplotlib.pyplot as plt
import numpy as np

# Extract applied treatment percentages from the dictionary
applied_treatment_percentages = [applied_treatment_percentage for _, applied_treatment_percentage in percentage_tracking_by_year.values()]

# Set positions for each bar
x_positions = np.arange(len(applied_treatment_percentages))

# Plotting the percentage of segments with applied treatments for each year
plt.figure(figsize=(12, 6))
plt.bar(x_positions, applied_treatment_percentages, color='teal', edgecolor='black')
plt.xlabel("Year")
plt.ylabel("Percentage of Segments with Applied Treatments (%)")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.title("Percentage of Segments with Applied Treatments per Year")
plt.xticks(x_positions, x_positions, ha="right")

plt.ylim(0, 100)  # Ensure the y-axis goes from 0 to 100%
plt.tight_layout()  # Adjust layout to fit x-tick labels
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def calculate_treatment_percentages(gdf, years=30):
    """
    Computes the percentage of each treatment over all treated lane miles for each year.
    """
    excluded_treatments = {'CONTINUE_TRACKING', 'DO_NOTHING', 'REPAIR', 'DIAMOND_GRIND'}

    # Compute calculated lane miles
    gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']

    results = []

    for year in range(years + 1):
        treatment_col = f'Treatment_Year_{year}'

        # Total lane miles for this year
        total_lane_miles = gdf['Calculated_Lane_Miles'].sum()

        # Group by treatments and sum the lane miles for each treatment
        treatment_lane_miles = gdf.groupby(treatment_col)['Calculated_Lane_Miles'].sum()

        # Calculate percentage for each treatment over total lane miles
        for treatment, lane_miles in treatment_lane_miles.items():
            if treatment not in excluded_treatments:
                percentage = (lane_miles / total_lane_miles) * 100 if total_lane_miles > 0 else 0
                results.append({
                    'Year': year,
                    'Treatment': treatment,
                    'Percentage': percentage
                })

    # Convert results into a DataFrame
    results_df = pd.DataFrame(results)

    return results_df

def plot_stacked_bar_chart(treatment_percentages_df):
    """
    Plots a stacked bar chart of treatment percentages using Seaborn.
    """
    # Set Seaborn style
    sns.set_style("whitegrid")

    # Get tab20 colors
    unique_treatments = treatment_percentages_df["Treatment"].unique()
    num_treatments = len(unique_treatments)
    tab20_colors = sns.color_palette("tab20", num_treatments)

    # Create a color mapping for treatments
    treatment_color_map = dict(zip(unique_treatments, tab20_colors))

    # Create a stacked bar chart using sns.barplot()
    fig, ax = plt.subplots(figsize=(14, 8))

    # Sort data by year for correct stacking
    treatment_percentages_df = treatment_percentages_df.sort_values(by=["Year", "Treatment"])

    # Plot each treatment as a layer in the stacked bar chart
    bottom_stack = np.zeros(len(treatment_percentages_df["Year"].unique()))  # Track bottom stack positions
    years = sorted(treatment_percentages_df["Year"].unique())  # Ensure years are in order

    for treatment in unique_treatments:
        subset = treatment_percentages_df[treatment_percentages_df["Treatment"] == treatment]
        ax.bar(subset["Year"], subset["Percentage"], label=treatment, color=treatment_color_map[treatment],
               bottom=bottom_stack[subset["Year"].values - years[0]], edgecolor="gray")
        bottom_stack[subset["Year"].values - years[0]] += subset["Percentage"].values  # Update stack position

    # Formatting
    ax.set_title("Stacked Bar Chart of Treatment Percentages by Year", fontsize=14)
    ax.set_xlabel("Year", fontsize=12)
    ax.set_ylabel("Percentage (%)", fontsize=12)
    ax.set_xticks(years)
    ax.set_xticklabels(years, rotation=0)
    #ax.set_ylim(0, 60)
    #ax.set_yticks(np.arange(0, 60, 10))
    ax.legend(title="Treatment", bbox_to_anchor=(1.05, 1), loc="upper left")
    ax.grid(axis="y", linestyle="--", alpha=0.7)

    plt.tight_layout()
    plt.show()

# ✅ Calculate treatment percentages
treatment_percentages_df = calculate_treatment_percentages(gdf, years=30)

# ✅ Plot using Seaborn (without boxes on top)
plot_stacked_bar_chart(treatment_percentages_df)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def calculate_treatment_percentages(gdf, years=30):
    excluded_treatments = {'CONTINUE_TRACKING', 'DO_NOTHING', 'REPAIR', 'DIAMOND_GRIND'}
    gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']
    results = []

    for year in range(years + 1):
        treatment_col = f'Treatment_Year_{year}'
        total_lane_miles = gdf['Calculated_Lane_Miles'].sum()
        treatment_lane_miles = gdf.groupby(treatment_col)['Calculated_Lane_Miles'].sum()

        for treatment, lane_miles in treatment_lane_miles.items():
            if treatment not in excluded_treatments:
                percentage = (lane_miles / total_lane_miles) * 100 if total_lane_miles > 0 else 0
                results.append({
                    'Year': year,
                    'Treatment': treatment,
                    'Percentage': percentage
                })

    return pd.DataFrame(results)

def plot_stacked_bar_chart(treatment_percentages_df, all_treatments):
    sns.set_style("whitegrid")

    # Fixed color map for all treatments
    color_palette = sns.color_palette("tab20", len(all_treatments))
    treatment_color_map = dict(zip(all_treatments, color_palette))

    fig, ax = plt.subplots(figsize=(14, 8))
    treatment_percentages_df = treatment_percentages_df.sort_values(by=["Year", "Treatment"])
    years = sorted(treatment_percentages_df["Year"].unique())
    bottom_stack = np.zeros(len(years))

    for treatment in all_treatments:
        subset = treatment_percentages_df[treatment_percentages_df["Treatment"] == treatment]
        if not subset.empty:
            ax.bar(
                subset["Year"],
                subset["Percentage"],
                label=treatment,
                color=treatment_color_map[treatment],
                bottom=bottom_stack[subset["Year"].values - years[0]],
                edgecolor="gray"
            )
            bottom_stack[subset["Year"].values - years[0]] += subset["Percentage"].values
        else:
            # Add invisible bar for legend
            ax.bar(0, 0, color=treatment_color_map[treatment], label=treatment)

    ax.set_title("Stacked Bar Chart of Treatment Percentages by Year", fontsize=14)
    ax.set_xlabel("Year", fontsize=12)
    ax.set_ylabel("Percentage (%)", fontsize=12)
    ax.set_xticks(years)
    ax.set_xticklabels(years, rotation=0)
    ax.set_ylim(0, 10)
    ax.set_yticks(np.arange(0, 10, 2))
    ax.legend(title="Treatment", bbox_to_anchor=(1.05, 1), loc="upper left")
    ax.grid(axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.show()


# 1. Get all possible treatments
treatments = list(import_draft_treatments(path).keys())  # or sorted(...)

# 2. Calculate percentages from current gdf
treatment_percentages_df = calculate_treatment_percentages(gdf, years=30)

# 3. Plot with fixed treatment color order
plot_stacked_bar_chart(treatment_percentages_df, treatments)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def calculate_treatment_percentages(gdf, years=30):
    """
    Computes the percentage of each treatment over all treated lane miles for each year.
    """
    excluded_treatments = {'CONTINUE_TRACKING', 'DO_NOTHING', 'REPAIR', 'DIAMOND_GRIND'}

    # Compute calculated lane miles
    gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']

    results = []
    treated_lane_miles_dict = {}

    for year in range(years + 1):
        treatment_col = f'Treatment_Year_{year}'

        # Filter out excluded treatments
        treated_gdf = gdf[~gdf[treatment_col].isin(excluded_treatments)]

        # Compute total treated lane miles for this year
        total_treated_lane_miles = treated_gdf['Calculated_Lane_Miles'].sum()
        treated_lane_miles_dict[year] = total_treated_lane_miles

        if total_treated_lane_miles > 0:
            # Group by treatments and sum the lane miles for each treatment
            treatment_lane_miles = treated_gdf.groupby(treatment_col)['Calculated_Lane_Miles'].sum()

            # Calculate percentage for each treatment over treated lane miles
            for treatment, lane_miles in treatment_lane_miles.items():
                percentage = (lane_miles / total_treated_lane_miles) * 100
                results.append({
                    'Year': year,
                    'Treatment': treatment,
                    'Percentage': percentage
                })

    # Convert results into a DataFrame
    results_df = pd.DataFrame(results)

    # Pivot table for easier plotting (Years as index, Treatments as columns)
    pivot_df = results_df.pivot(index='Year', columns='Treatment', values='Percentage').fillna(0)

    return pivot_df, treated_lane_miles_dict

def plot_stacked_bar_chart(treatment_percentages_pivot, treated_lane_miles_dict):
    """
    Plots a stacked bar chart of treatment percentages with total treated lane miles displayed in a box above each bar.
    """
    # Seaborn style settings (to match Code 2)
    sns.set_style("whitegrid")
    plt.rcParams["axes.facecolor"] = "white"
    plt.rcParams["figure.facecolor"] = "white"
    plt.rcParams["grid.color"] = "#d3d3d3"
    plt.rcParams["grid.linestyle"] = "--"
    plt.rcParams["grid.alpha"] = 0.7
    plt.rcParams["axes.edgecolor"] = "black"
    plt.rcParams["axes.linewidth"] = 1.2

    fig, ax = plt.subplots(figsize=(14, 10))  # Match Code 2's size

    # Use the correct tab20 color map
    cmap = plt.get_cmap("tab20").colors  # Extracts 20 distinct colors

    unique_treatments = list(treatment_percentages_pivot.columns)
    num_treatments = len(unique_treatments)

    # Assign colors dynamically to treatments using tab20's color order
    treatment_color_map = {treatment: cmap[i % 20] for i, treatment in enumerate(unique_treatments)}

    # Plot stacked bar chart with tab20 colors and black edges
    bars = treatment_percentages_pivot.plot(
        kind='bar', stacked=True, ax=ax, color=[treatment_color_map[t] for t in unique_treatments],
        edgecolor='black'
    )

    # Formatting axes
    ax.set_ylabel("Percentage of Treated Lane Miles (%)", fontsize=12)
    ax.set_ylim(0, 110)  # Slightly above 100 for labels
    ax.set_xlabel("Year", fontsize=12)

    # Set x-ticks to be horizontal (like Code 2)
    ax.set_xticks(range(len(treatment_percentages_pivot.index)))
    ax.set_xticklabels(treatment_percentages_pivot.index, rotation=0)

    # Add grid lines (dashed for y-axis, no x-axis grid)
    plt.grid(axis="y", linestyle="--", alpha=0.7)

    # ✅ Add total treated lane miles as text above bars (like Code 2)
    for i, year in enumerate(treatment_percentages_pivot.index):
        treated_miles = treated_lane_miles_dict.get(year, 0)
        if treated_miles > 0:
            ax.text(i, 104, f"{treated_miles:,.0f}", ha='center', fontsize=10, fontweight='bold',
                    bbox=dict(facecolor='white', alpha=0.8, edgecolor='black'), rotation=90)

    # ✅ Legend outside the plot for clarity
    ax.legend(title="Treatment Type", bbox_to_anchor=(1.05, 1), loc="upper left")

    plt.tight_layout()
    plt.show()

# ✅ Calculate the treatment percentages as a pivot table and total treated lane miles
treatment_percentages_pivot, treated_lane_miles_dict = calculate_treatment_percentages(gdf, years=30)

# ✅ Plot the stacked bar chart with correct tab20 colors
plot_stacked_bar_chart(treatment_percentages_pivot, treated_lane_miles_dict)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def calculate_treatment_percentages(gdf, all_treatments, years=30):
    """
    Computes the percentage of each treatment over all treated lane miles for each year.
    Ensures all treatments are present in the output even if not used.
    """
    excluded_treatments = {'CONTINUE_TRACKING', 'DO_NOTHING', 'REPAIR', 'DIAMOND_GRIND'}
    gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']

    results = []
    treated_lane_miles_dict = {}

    for year in range(years + 1):
        treatment_col = f'Treatment_Year_{year}'
        treated_gdf = gdf[~gdf[treatment_col].isin(excluded_treatments)]
        total_treated_lane_miles = treated_gdf['Calculated_Lane_Miles'].sum()
        treated_lane_miles_dict[year] = total_treated_lane_miles

        treatment_lane_miles = treated_gdf.groupby(treatment_col)['Calculated_Lane_Miles'].sum().to_dict()

        for treatment in all_treatments:
            if treatment not in excluded_treatments:
                lane_miles = treatment_lane_miles.get(treatment, 0)
                percentage = (lane_miles / total_treated_lane_miles) * 100 if total_treated_lane_miles > 0 else 0
                results.append({
                    'Year': year,
                    'Treatment': treatment,
                    'Percentage': percentage
                })

    results_df = pd.DataFrame(results)
    pivot_df = results_df.pivot(index='Year', columns='Treatment', values='Percentage').fillna(0)
    return pivot_df, treated_lane_miles_dict

def plot_stacked_bar_chart(treatment_percentages_pivot, treated_lane_miles_dict, all_treatments):
    """
    Plots a stacked bar chart with fixed color mapping and full legend based on all treatments.
    """
    sns.set_style("whitegrid")
    plt.rcParams["axes.facecolor"] = "white"
    plt.rcParams["figure.facecolor"] = "white"
    plt.rcParams["grid.color"] = "#d3d3d3"
    plt.rcParams["grid.linestyle"] = "--"
    plt.rcParams["grid.alpha"] = 0.7
    plt.rcParams["axes.edgecolor"] = "black"
    plt.rcParams["axes.linewidth"] = 1.2

    fig, ax = plt.subplots(figsize=(14, 10))

    # Tab20 color map (repeat colors if needed)
    cmap = plt.get_cmap("tab20").colors
    treatment_color_map = {treatment: cmap[i % len(cmap)] for i, treatment in enumerate(all_treatments)}

    # Reindex pivot to ensure all treatments are included in correct order
    treatment_percentages_pivot = treatment_percentages_pivot.reindex(columns=all_treatments, fill_value=0)

    # Plot the stacked bar chart
    treatment_percentages_pivot.plot(
        kind='bar',
        stacked=True,
        ax=ax,
        color=[treatment_color_map[t] for t in all_treatments],
        edgecolor='black'
    )

    ax.set_ylabel("Percentage of Treated Lane Miles (%)", fontsize=12)
    ax.set_ylim(0, 110)
    ax.set_xlabel("Year", fontsize=12)
    ax.set_xticks(range(len(treatment_percentages_pivot.index)))
    ax.set_xticklabels(treatment_percentages_pivot.index, rotation=0)
    ax.grid(axis="y", linestyle="--", alpha=0.7)

    # Add treated lane miles above bars
    for i, year in enumerate(treatment_percentages_pivot.index):
        treated_miles = treated_lane_miles_dict.get(year, 0)
        if treated_miles > 0:
            ax.text(i, 104, f"{treated_miles:,.0f}", ha='center', fontsize=10, fontweight='bold',
                    bbox=dict(facecolor='white', alpha=0.8, edgecolor='black'), rotation=90)

    # Full legend
    ax.legend(title="Treatment Type", bbox_to_anchor=(1.05, 1), loc="upper left")
    plt.tight_layout()
    plt.show()

# ✅ Example usage:
all_treatments = list(import_draft_treatments(path).keys())  # Get full treatment list
treatment_percentages_pivot, treated_lane_miles_dict = calculate_treatment_percentages(gdf, all_treatments, years=30)
plot_stacked_bar_chart(treatment_percentages_pivot, treated_lane_miles_dict, all_treatments)

# Treatment to Budget Category mapping from the table
treatment_to_category = {
    'CPR': 'Preservation',
    'CRACKSEAL': 'Preservation',
    'CRACKSEAL_AND_CHIPSEAL': 'Preservation',
    'FOG_COAT': 'Preservation',
    'MILL_FR_AND_MICRO_CAPE_SEAL': 'Preservation',
    'MS_1_PASS': 'Preservation',
    'MS_2_PASS': 'Preservation',
    'RR_0p5INCH_FR': 'Preservation',
    'RR_1INCH_FR': 'Preservation',
    'RR_2INCH_AC_FR': 'Major_Projects',
    'RR_2p5INCH_AC_FR': 'Major_Projects',
    'RR_3INCH_AC_FR': 'Major_Projects',
    'RR_4INCH_AC_FR': 'Major_Projects',
    'RR_5INCH_AC_FR': 'Major_Projects',
    'SR_3INCH_AC_MS': 'Major_Projects',
    'MAJOR_REHAB_OR_RECONSTRUCTION': 'Major_Projects',
    'RECONSTRUCTION': 'Reconstruction',
    'DIAMOND_GRIND': 'Excluded',
    'REPAIR': 'Excluded',
    'CONTINUE_TRACKING': 'DO_NOTHING',
    'DO_NOTHING': 'DO_NOTHING',
}

# Efficiently map treatment to group for years 0 to 30
for year in range(31):
    treatment_col = f'Treatment_Year_{year}'
    group_col = f'Treatment_Group_Y_{year}'
    gdf[group_col] = gdf[treatment_col].map(treatment_to_category)

def calculate_grouped_treatment_percentages(gdf, treatment_to_category, years=30):
    excluded_treatments = {'Excluded', 'DO_NOTHING'}

    # Lane-miles calculation (done once)
    gdf['Calculated_Lane_Miles'] = (gdf['ToMeasure'] - gdf['FromMeasur']) * gdf['Number_of_']
    results = []

    for year in range(years + 1):
        treatment_col = f'Treatment_Year_{year}'
        group_col = f'Treatment_Group_Y_{year}'

        # Total lane miles must include all rows (not just filtered ones)
        total_lane_miles = gdf['Calculated_Lane_Miles'].sum()

        # Filter out excluded treatments for group-by only
        filtered_gdf = gdf[~gdf[treatment_col].isin(excluded_treatments)]
        group_lane_miles = filtered_gdf.groupby(group_col)['Calculated_Lane_Miles'].sum()

        for group, lane_miles in group_lane_miles.items():
            if pd.notna(group) and group != '':
                percentage = (lane_miles / total_lane_miles) * 100 if total_lane_miles > 0 else 0
                results.append({
                    'Year': year,
                    'Treatment Group': group,
                    'Percentage': percentage
                })

    return pd.DataFrame(results)



def plot_grouped_stacked_bar_chart(grouped_df):
    sns.set_style("whitegrid")

    # Groups you want to exclude from the plot
    excluded_groups = {'Excluded', 'DO_NOTHING'}

    # Filter out the excluded groups from the plot data
    grouped_df = grouped_df[~grouped_df["Treatment Group"].isin(excluded_groups)]

    # Use distinct colors for each remaining group
    groups = sorted(grouped_df["Treatment Group"].unique())
    color_palette = sns.color_palette("tab20", len(groups))
    group_color_map = dict(zip(groups, color_palette))

    fig, ax = plt.subplots(figsize=(14, 8))
    grouped_df = grouped_df.sort_values(by=["Year", "Treatment Group"])
    years = sorted(grouped_df["Year"].unique())
    bottom_stack = np.zeros(len(years))

    for group in groups:
        subset = grouped_df[grouped_df["Treatment Group"] == group]
        if not subset.empty:
            ax.bar(
                subset["Year"],
                subset["Percentage"],
                label=group,
                color=group_color_map[group],
                bottom=bottom_stack[subset["Year"].values - years[0]],
                edgecolor="gray"
            )
            bottom_stack[subset["Year"].values - years[0]] += subset["Percentage"].values
        else:
            ax.bar(0, 0, color=group_color_map[group], label=group)

    ax.set_title("Stacked Bar Chart of Treatment Group Percentages by Year", fontsize=14)
    ax.set_xlabel("Year", fontsize=12)
    ax.set_ylabel("Percentage (%)", fontsize=12)
    ax.set_xticks(years)
    ax.set_xticklabels(years, rotation=0)
    ax.set_ylim(0, 10)
    ax.set_yticks(np.arange(0, 10, 2))
    ax.legend(title="Treatment Group", bbox_to_anchor=(1.05, 1), loc="upper left")
    ax.grid(axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.show()



# Run the grouped version
grouped_percentages_df = calculate_grouped_treatment_percentages(gdf, treatment_to_category, years=30)
plot_grouped_stacked_bar_chart(grouped_percentages_df)

import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.lines as mlines
import contextily as ctx
import matplotlib.cm as cm


# Clean and prepare
#treatments_gdf['Treatment_Year_0'] = treatments_gdf['Treatment_Year_0'].fillna('Unknown')
#treatments_gdf['Treatment_Year_0'] = treatments_gdf['Treatment_Year_0'].astype(str).str.strip().astype('category')

gdf['Treatment_Year_0'] = (
    gdf['Treatment_Year_0']
    .astype(str)
    .str.strip()
    .replace('nan', 'Unknown')  # replaces string "nan" left from NaN
    .astype('category')
)

# Convert polygons to boundary lines
gdf['geometry'] = gdf.boundary

# Reproject for basemap
gdf = gdf.to_crs(epsg=3857)

# Prepare color mapping
categories = gdf['Treatment_Year_0'].cat.categories
cmap = cm.get_cmap('tab20', len(categories))
color_map = {cat: cmap(i) for i, cat in enumerate(categories)}

# Set up plot
fig, ax = plt.subplots(figsize=(20, 15))

# Plot each pavement type with its color
for cat in categories:
    subset = gdf[gdf['Treatment_Year_0'] == cat]
    subset.plot(ax=ax, color=color_map[cat], linewidth=1.5, alpha=1)

# Add basemap
ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=gdf.crs) #CartoDB.Voyager for colored

# Custom legend
legend_handles = [
    mlines.Line2D([], [], color=color_map[cat], linewidth=3, label=cat)
    for cat in categories
]
ax.legend(handles=legend_handles, title='Treatment Type', loc='lower left')

# Final layout
ax.set_title('Arizona Roads by Treatment Type (Year 0)', fontsize=20)
ax.set_axis_off()
plt.tight_layout()
plt.show()

# Using Quantile Bins (better visualization)
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import contextily as ctx
import numpy as np
import pandas as pd

# Make sure we have valid Cost_Year_0
gdf = gdf[gdf['Cost_Year_0'].notna()].copy()
gdf = gdf.to_crs(epsg=3857)

# Separate zeros into a separate bin
zero_mask = gdf['Cost_Year_0'] == 0
non_zero_gdf = gdf[~zero_mask]  # Data without zero costs
zero_gdf = gdf[zero_mask]  # Data with zero costs

# Define quantile bins (for non-zero values)
n_bins = 3  # Reduced number of bins for non-zero values, as 1 bin is reserved for zeros
labels = [f'Q{i+1}' for i in range(n_bins)]  # Correct number of labels for the bins

# Use pd.qcut to divide the non-zero data into quantiles
non_zero_gdf['Cost_0_BIN'], bin_edges = pd.qcut(non_zero_gdf['Cost_Year_0'], q=n_bins, labels=labels, retbins=True, duplicates='drop')

# Combine the zero bin with the quantile bins
gdf['Cost_0_BIN'] = 'Q0'  # Default for zeros
gdf.loc[~zero_mask, 'Cost_0_BIN'] = non_zero_gdf['Cost_0_BIN'].values

# Set up color mapping (discrete)
cmap = cm.get_cmap('viridis', n_bins + 1)  # +1 for the 'zero' bin
colors = [cmap(i) for i in range(n_bins + 1)]  # Colors for zero bin and quantiles
color_dict = dict(zip(['Q0'] + labels, colors))  # Include zero bin

# Plot
fig, ax = plt.subplots(figsize=(20, 15))

# Plot zeros in a separate color
gdf[gdf['Cost_0_BIN'] == 'Q0'].plot(ax=ax, color=color_dict['Q0'], linewidth=1.5, alpha=0.9, label='Zero Cost')

# Plot the quantiles
for label in labels:
    subset = gdf[gdf['Cost_0_BIN'] == label]
    subset.plot(
        ax=ax,
        color=color_dict[label],
        linewidth=1.5,
        alpha=0.9,
        label=label
    )

# Add basemap
ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=gdf.crs)

# Custom legend with actual bin ranges (for quantiles)
legend_labels = [
    f"{int(bin_edges[i]):,} – {int(bin_edges[i+1]):,}" for i in range(len(bin_edges)-1)
]
from matplotlib.lines import Line2D
handles = [
    Line2D([], [], color=colors[i+1], linewidth=3, label=legend_labels[i])  # Shift index by 1 for quantiles
    for i in range(n_bins)
]
handles.insert(0, Line2D([], [], color=colors[0], linewidth=3, label='0'))  # Add zero bin legend
ax.legend(handles=handles, title='Cost for year 0 (Quantiles)', loc='lower left', fontsize=12)

# Layout
ax.set_title('Arizona Roads Colored by Cost (Year 0)', fontsize=20)
ax.set_axis_off()
plt.tight_layout()
plt.show()

print(len(gdf['MR_Emission_Year_0']))

# Using Quantile Bins (better visualization)
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import contextily as ctx
import numpy as np
import pandas as pd

# Make sure we have valid Cost_Year_0
gdf = gdf[gdf['MR_Emission_Year_0'].notna()].copy()
gdf = gdf.to_crs(epsg=3857)

print(gdf['MR_Emission_Year_0'].value_counts().head(10))  # Check the most common values


# Separate zeros into a separate bin
zero_mask = gdf['MR_Emission_Year_0'] == 0
non_zero_gdf = gdf[~zero_mask]  # Data without zero costs
zero_gdf = gdf[zero_mask]  # Data with zero costs

# Define quantile bins (for non-zero values)
n_bins = 3  # Reduced number of bins for non-zero values, as 1 bin is reserved for zeros
labels = [f'Q{i+1}' for i in range(n_bins)]  # Correct number of labels for the bins

# Use pd.qcut to divide the non-zero data into quantiles
non_zero_gdf['MR_0_BIN'], bin_edges = pd.qcut(non_zero_gdf['MR_Emission_Year_0'], q=n_bins, labels=labels, retbins=True, duplicates='drop')

# Combine the zero bin with the quantile bins
gdf['MR_0_BIN'] = 'Q0'  # Default for zeros
gdf.loc[~zero_mask, 'MR_0_BIN'] = non_zero_gdf['MR_0_BIN'].values

# Set up color mapping (discrete)
cmap = cm.get_cmap('viridis', n_bins + 1)  # +1 for the 'zero' bin
colors = [cmap(i) for i in range(n_bins + 1)]  # Colors for zero bin and quantiles
color_dict = dict(zip(['Q0'] + labels, colors))  # Include zero bin

# Plot
fig, ax = plt.subplots(figsize=(20, 15))

# Plot zeros in a separate color
gdf[gdf['MR_0_BIN'] == 'Q0'].plot(ax=ax, color=color_dict['Q0'], linewidth=1.5, alpha=0.9, label='Zero Cost')

# Plot the quantiles
for label in labels:
    subset = gdf[gdf['MR_0_BIN'] == label]
    subset.plot(
        ax=ax,
        color=color_dict[label],
        linewidth=1.5,
        alpha=0.9,
        label=label
    )

# Add basemap
ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=gdf.crs)

# Custom legend with actual bin ranges (for quantiles)
legend_labels = [
    f"{int(bin_edges[i]):,} – {int(bin_edges[i+1]):,}" for i in range(len(bin_edges)-1)
]
from matplotlib.lines import Line2D
handles = [
    Line2D([], [], color=colors[i+1], linewidth=3, label=legend_labels[i])  # Shift index by 1 for quantiles
    for i in range(n_bins)
]
handles.insert(0, Line2D([], [], color=colors[0], linewidth=3, label='0'))  # Add zero bin legend
ax.legend(handles=handles, title='MR Emission for year 0 (Quantiles)', loc='lower left', fontsize=12)

# Layout
ax.set_title('Arizona Roads Colored by MR Emission (Year 0)', fontsize=20)
ax.set_axis_off()
plt.tight_layout()
plt.show()

# Using Quantile Bins (better visualization)
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import contextily as ctx
import numpy as np
import pandas as pd

# Make sure we have valid Cost_Year_0
gdf = gdf[gdf['total_CO2_0year'].notna()].copy()
gdf = gdf.to_crs(epsg=3857)

print(gdf['total_CO2_0year'].value_counts().head(10))  # Check the most common values


# Separate zeros into a separate bin
zero_mask = gdf['total_CO2_0year'] == 0
non_zero_gdf = gdf[~zero_mask]  # Data without zero costs
zero_gdf = gdf[zero_mask]  # Data with zero costs

# Define quantile bins (for non-zero values)
n_bins = 3  # Reduced number of bins for non-zero values, as 1 bin is reserved for zeros
labels = [f'Q{i+1}' for i in range(n_bins)]  # Correct number of labels for the bins

# Use pd.qcut to divide the non-zero data into quantiles
non_zero_gdf['USE_0_BIN'], bin_edges = pd.qcut(non_zero_gdf['total_CO2_0year'], q=n_bins, labels=labels, retbins=True, duplicates='drop')

# Combine the zero bin with the quantile bins
gdf['USE_0_BIN'] = 'Q0'  # Default for zeros
gdf.loc[~zero_mask, 'USE_0_BIN'] = non_zero_gdf['USE_0_BIN'].values

# Set up color mapping (discrete)
cmap = cm.get_cmap('viridis', n_bins + 1)  # +1 for the 'zero' bin
colors = [cmap(i) for i in range(n_bins + 1)]  # Colors for zero bin and quantiles
color_dict = dict(zip(['Q0'] + labels, colors))  # Include zero bin

# Plot
fig, ax = plt.subplots(figsize=(20, 15))

# Plot zeros in a separate color
gdf[gdf['USE_0_BIN'] == 'Q0'].plot(ax=ax, color=color_dict['Q0'], linewidth=1.5, alpha=0.9, label='0')

# Plot the quantiles
for label in labels:
    subset = gdf[gdf['USE_0_BIN'] == label]
    subset.plot(
        ax=ax,
        color=color_dict[label],
        linewidth=1.5,
        alpha=0.9,
        label=label
    )

# Add basemap
ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=gdf.crs)

# Custom legend with actual bin ranges (for quantiles)
legend_labels = [
    f"{bin_edges[i]:.1e} – {bin_edges[i+1]:.1e}"
    for i in range(len(bin_edges) - 1)
]
from matplotlib.lines import Line2D
handles = [
    Line2D([], [], color=colors[i+1], linewidth=3, label=legend_labels[i])  # Shift index by 1 for quantiles
    for i in range(n_bins)
]
handles.insert(0, Line2D([], [], color=colors[0], linewidth=3, label='0'))  # Add zero bin legend
ax.legend(handles=handles, title='Use Stage Emission for year 0 (Quantiles)', loc='lower left', fontsize=12)

# Layout
ax.set_title('Arizona Roads Colored by Use Stage Emission (Year 0)', fontsize=20)
ax.set_axis_off()
plt.tight_layout()
plt.show()

print(gdf['Treatment_Year_0'].count())
print(gdf['Cost_Year_0'].count())
print(gdf['MR_Emission_Year_0'].count())

import matplotlib.pyplot as plt
import numpy as np

# Extract years (0 to 30)
years = list(range(0, 31))

# Extract use-stage emissions data (Code 1)
vehicle_types = ['Passenger Vehicle', 'Small Truck', 'Medium Truck', 'Large Truck']
use_stage_emissions = {vehicle: [] for vehicle in vehicle_types}

for year in years:  # Match years 0 to 30
    for vehicle in vehicle_types:
        use_stage_emissions[vehicle].append(yearly_co2_totals[year].get(vehicle, 0))

# Convert use-stage emissions to NumPy array for easier manipulation
use_stage_emissions_np = np.array([use_stage_emissions[vehicle] for vehicle in vehicle_types])

# Sum the use-stage emissions across all vehicle types for each year
total_use_stage_emissions = np.sum(use_stage_emissions_np, axis=0)  # Sum by column (years)

# Extract maintenance and rehabilitation emissions data (Code 2)
maintenance_emissions = [yearly_emissions[year]['Total'] / 1e9 for year in years]  # Convert to MMT

# Ensure both data sources are aligned by years
assert len(total_use_stage_emissions) == len(maintenance_emissions)

# Combine both stages for stacking
combined_emissions = {
    'Use Stage': total_use_stage_emissions,
    'Maintenance and Rehabilitation': maintenance_emissions,
}

# Colors for each stage
colors = ['steelblue', 'orange']

# Initialize the bottom positions for the stacked bars
bottom = np.zeros(len(years))

# Create the figure and axis objects
fig, ax = plt.subplots(figsize=(14, 8))

# Plot each stage's emissions as a stacked bar
for stage, color in zip(combined_emissions.keys(), colors):
    ax.bar(years, combined_emissions[stage], bottom=bottom, color=color, label=stage)
    bottom += combined_emissions[stage]  # Update the bottom for stacking

# Set labels and title
ax.set_xlabel('Years')
ax.set_ylabel('Total CO₂-equiv Emissions (MMT)')
ax.set_title('Total CO₂ Emissions by Stage (Use and Maintenance)')

# Set x-ticks for selected years
ax.set_xticks(range(0, 31, 5))  # Tick marks every 5 years
ax.set_xticklabels(range(0, 31, 5))

# Add a legend to identify stages
ax.legend(loc='upper left', fontsize='large', frameon=True, bbox_to_anchor=(0.1, 0.98))

# Add grid lines for clarity
ax.grid(axis='y', linestyle='--', alpha=0.7)

plt.ylim(0, 0.8)
plt.yticks(np.arange(0, 0.9, 0.1))

# Adjust layout for a clean appearance
plt.tight_layout()

# Display the plot
plt.show()